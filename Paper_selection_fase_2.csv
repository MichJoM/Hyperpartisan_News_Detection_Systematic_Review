key,title,year,month,day,journal,issn,volume,issue,pages,authors,url,language,publisher,location,abstract,notes,doi,keywords,pubmed_id,pmc_id
rayyan-1120387402,Cultural Fault Lines and Political Polarization,2017,,,Proceedings of the 2017 ACM on Web Science Conference,9781450348966,,,213–217,"Shi, Yongren and Mast, Kai and Weber, Ingmar and Kellum, Agrippa and Macy, Michael",https://doi.org/10.1145/3091478.3091520,,Association for Computing Machinery,"Troy, New York, USA",,not_pertinent,10.1145/3091478.3091520,culture;polarization;social media;networks,,
rayyan-1120387403,"Understanding Political Polarization via Jointly Modeling Users, Connections and Multimodal Contents on Heterogeneous Graphs",2022,,,Proceedings of the 30th ACM International Conference on Multimedia,9781450392037,,,4072–4082,"Lyu, Hanjia and Luo, Jiebo",https://doi.org/10.1145/3503161.3547898,,Association for Computing Machinery,"Lisboa, Portugal",,other_method,10.1145/3503161.3547898,political polarization;user-content interaction;heterogeneous graph;multimedia,,
rayyan-1120387404,Content and Network Dynamics Behind Egyptian Political Polarization on Twitter,2015,,,Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing,9781450329224,,,700–711,"Borge-Holthoefer, Javier and Magdy, Walid and Darwish, Kareem and Weber, Ingmar",https://doi.org/10.1145/2675133.2675163,,Association for Computing Machinery,"Vancouver, BC, Canada",,not_pertinent_data,10.1145/2675133.2675163,opinion switch;polarization;mobilization;egypt;twitter,,
rayyan-1120387405,Studying Political Bias via Word Embeddings,2020,,,Companion Proceedings of the Web Conference 2020,9781450370240,,,760–764,"Gordon, Joshua and Babaeianjelodar, Marzieh and Matthews, Jeanna",https://doi.org/10.1145/3366424.3383560,,Association for Computing Machinery,"Taipei, Taiwan",,not_pertinent_data,10.1145/3366424.3383560,natural language processing;political bias;Twitter dataset;Bias (Epidemiology),,
rayyan-1120387406,A Transformer-based Framework for Neutralizing and Reversing the Political Polarity of News Articles,2021,,,Proc. ACM Hum.-Comput. Interact.,,5,,Article 65,"Liu, Ruibo and Jia, Chenyan and Vosoughi, Soroush",https://doi.org/10.1145/3449139,,Association for Computing Machinery,,,other_task,10.1145/3449139,selective exposure;transformer-based models;neural networks;political polarization;echo chamber;journalism;automatic polarity transfer,,
rayyan-1120387407,"That's Fake News! Reliability of News When Provided Title, Image, Source Bias &amp; Full Article",2021,,,Proc. ACM Hum.-Comput. Interact.,,5,,Article 109,"Spezzano, Francesca and Shrestha, Anu and Fails, Jerry Alan and Stone, Brian W.",https://doi.org/10.1145/3449183,,Association for Computing Machinery,,,other_task,10.1145/3449183,meta-data analysis;news credibility;fake news;Bias (Epidemiology);Adenosine Monophosphate,,
rayyan-1120387408,Ideology Detection of Personalized Political News Coverage: A New Dataset,2020,,,Proceedings of the 2020 the 4th International Conference on Compute and Data Analysis,9781450376440,,,10–15,"Alzhrani, Khudran",https://doi.org/10.1145/3388142.3388149,,Association for Computing Machinery,"Silicon Valley, CA, USA",,included,10.1145/3388142.3388149,Neural Language Processing;Machine Learning;Text Classification;Political Science;News Personalization;News Bias,,
rayyan-1120387409,The POLUSA Dataset: 0.9M Political News Articles Balanced by Time and Outlet Popularity,2020,,,Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020,9781450375856,,,467–468,"Gebhard, Lukas and Hamborg, Felix",https://doi.org/10.1145/3383583.3398567,,Association for Computing Machinery,"Virtual Event, China",,included,10.1145/3383583.3398567,corpus;media bias;natural language processing;cc-news;computational social sciences;text mining;us politics,,
rayyan-1120387410,Fake News vs Satire: A Dataset and Analysis,2018,,,Proceedings of the 10th ACM Conference on Web Science,9781450355636,,,17–21,"Golbeck, Jennifer and Mauriello, Matthew and Auxier, Brooke and Bhanushali, Keval H. and Bonk, Christopher and Bouzaghrane, Mohamed Amine and Buntain, Cody and Ch, Riya and uka and Cheakalos, Paul and Everett, Jennine B. and Falak, Waleed and Gieringer, Carl and Graney, Jack and Hoffman, Kelly M. and Huth, Lindsay and Ma, Zhenya and Jha, Mayanka and Khan, Misbah and Kori, Varsha and Lewis, Elo and Mirano, George and IV, William T. Mohn and Mussenden, Sean and Nelson, Tammie M. and Mcwillie, Sean and Pant, Akshat and Shetye, Priya and Shrestha, Rusha and Alex and ra Steinheimer and Subramanian, Aditya and Visnansky, Gina",https://doi.org/10.1145/3201064.3201100,,Association for Computing Machinery,"Amsterdam, Netherlands",,not_pertinent_data,10.1145/3201064.3201100,classification;datasets;fake news,,
rayyan-1120387411,Ideology detection in the indian mass media,2021,,,Proceedings of the 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,9781728110561,,,627–634,"Sharma, Ankur and Kaur, Navreet and Sen, Anirban and Seth, Aaditeshwar",https://doi.org/10.1109/ASONAM49781.2020.9381344,,IEEE Press,"Virtual Event, Netherlands",,included,10.1109/ASONAM49781.2020.9381344,media bias;recursive neural networks;sentiment analysis;ideology classification;social media analysis;ideology detection;social policy;mass media analysis;Mass Media,,
rayyan-1120387412,POLAR: a holistic framework for the modelling of polarization and identification of polarizing topics in news media,2022,,,Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,9781450391283,,,348–355,"Paschalides, Demetris and Pallis, George and Dikaiakos, Marios D.",https://doi.org/10.1145/3487351.3489443,,Association for Computing Machinery,"Virtual Event, Netherlands",,other_method,10.1145/3487351.3489443,signed networks;polarization;inter-group conflict;polarizing topic extraction;natural language processing,,
rayyan-1120387413,KHAN: Knowledge-Aware Hierarchical Attention Networks for Accurate Political Stance Prediction,2023,,,Proceedings of the ACM Web Conference 2023,9781450394161,,,1572–1583,"Ko, Yunyong and Ryu, Seongeun and Han, Soeun and Jeon, Youngseung and Kim, Jaehoon and Park, Sohyun and Han, Kyungsik and Tong, Hanghang and Kim, Sang-Wook",https://doi.org/10.1145/3543507.3583300,,Association for Computing Machinery,"Austin, TX, USA",,included,10.1145/3543507.3583300,knowledge graph embedding;political stance prediction;echo chamber effect;hierarchical attention networks,,
rayyan-1120387414,HyperPT: detection and classification of hyperpartisan news articles,2021,,,,,,,,"Muscat, Mark",,,,,,not_pertinent_document,,,,
rayyan-1120387415,Computational Assessment of Hyperpartisanship in News Titles,2023,,,arXiv preprint arXiv:2301.06270,,,,,"Lyu, Hanjia and Pan, Jinsheng and Wang, Zichen and Luo, Jiebo",,,,,,included,,,,
rayyan-1120387416,Semisupervised Federated Learning for Temporal News Hyperpatism Detection,2023,,,IEEE Transactions on Computational Social Systems,,,,,"Ahmed, Usman and Lin, Jerry Chun-Wei and Srivastava, Gautam",,,IEEE,,,included,,Learning,,
rayyan-1120387417,Blowing on the Fire: An Analysis of Low Quality and Hyper Partisan News Sources Circulated by Coordinated Link Sharing Networks in Nigeria,2022,,,Available at SSRN 4162030,,,,,"Giglietto, Fabio and Olaniran, Samuel and Mincigrucci, Roberto and Marino, Giada and Mottola, Serena and Terenzi, Massimo",,,,,,other_method,,Nigeria,,
rayyan-1120387418,We can detect your bias: Predicting the political ideology of news articles,2020,,,arXiv preprint arXiv:2010.05338,,,,,"Baly, Ramy and Martino, Giovanni Da San and Glass, James and Nakov, Preslav",,,,,,included,,Bias (Epidemiology),,
rayyan-1120387419,Bias Bubbles: Using Semi-Supervised Learning to Measure How Many Biased News Articles Are Around Us. - AICS - AICS,2021,,,,,,,153--164,"Ruan, Qin and Mac Namee, Brian and Dong, Ruihai",,,,,,included,,Bias (Epidemiology),,
rayyan-1120387420,Fake and Hyper-partisan News Identification. - RoCHI - RoCHI,2019,,,,,,,60--67,"Dumitru, Vlad Cristian and Rebedea, Traian",,,,,,included,,,,
rayyan-1120387421,Brenda starr at SemEval-2019 task 4: hyperpartisan news detection - Proceedings of the 13th International Workshop on Semantic Evaluation - Proceedings of the 13th International Workshop on Semantic Evaluation,2019,,,,,,,924--928,"Papadopoulou, Olga and Kordopatis-Zilos, Giorgos and Zampoglou, Markos and Papadopoulos, Symeon and Kompatsiaris, Yiannis",,,,,,duplicate,,Semantics,,
rayyan-1120387422,From Fake to Hyperpartisan News Detection Using Domain Adaptation,2023,,,arXiv preprint arXiv:2308.02185,,,,,"Sm{\u{a}}du, R{\u{a}}zvan-Alex and ru and Echim, Sebastian-Vasile and Cercel, Dumitru-Clementin and Marin, Iuliana and Pop, Florin",,,,,,included,,,,
rayyan-1120387423,Classifying hyper-partisan news: Using linguistic analysis to predict the political orientation of news,2021,,,,,,,,"Groeneweg, Max",,,,,,not_pertinent_document,,,,
rayyan-1120387424,Shareworthiness and motivated reasoning in hyper-partisan news sharing behavior on Twitter,2021,,,Digital Journalism,,9,5,549--570,"Wischnewski, Magdalena and Bruns, Axel and Keller, Tobias",,,Taylor \& Francis,,,not_pertinent_data,,Motivation,,
rayyan-1120387425,CLoSE: Contrastive Learning of Subframe Embeddings for Political Bias Classification of News Media - Proceedings of the 29th International Conference on Computational Linguistics - Proceedings of the 29th International Conference on Computational Linguistics,2022,,,,,,,2780--2793,"Kim, Michelle YoungJin and Johnson, Kristen",,,,,,included,,Bias (Epidemiology),,
rayyan-1120387426,Sampling the news producers: A large news and feature data set for the study of the complex media landscape - Proceedings of the International AAAI Conference on Web and Social Media - Proceedings of the International AAAI Conference on Web and Social Media,2018,,,,,12,1,,"Horne, Benjamin and Khedr, Sara and Adali, Sibel",,,,,,not_pertinent_data,,,,
rayyan-1120387427,"Fane-kg: A semantic knowledge graph for context-based fake news detection on social media - 2020 Seventh International Conference on Social Networks Analysis, Management and Security (SNAMS) - 2020 Seventh International Conference on Social Networks Analysis, Management and Security (SNAMS)",2020,,,,,,,1--6,"Hani, Anoud Bani and Adedugbe, Oluwasegun and Al-Obeidat, Feras and Benkhelifa, Elhadj and Majdalawieh, Munir",,,,,,other_method,,Social Support;Semantics,,
rayyan-1120387428,A semantic model for context-based fake news detection on social media - 2020 IEEE/ACS 17th International Conference on Computer Systems and Applications (AICCSA) - 2020 IEEE/ACS 17th International Conference on Computer Systems and Applications (AICCSA),2020,,,,,,,1--7,"Bani-Hani, Anoud and Adedugbe, Oluwasegun and Benkhelifa, Elhadj and Majdalawieh, Munir and Al-Obeidat, Feras",,,,,,other_task,,Computer Systems;Semantics,,
rayyan-1120387429,Temporal positional lexicon expansion for federated learning based on hyperpatism detection,2023,,,Expert Systems,,40,5,e13183,"Ahmed, Usman and Lin, Jerry Chun-Wei and Srivastava, Gautam",,,Wiley Online Library,,,included,,Learning,,
rayyan-1120387430,Weakly supervised learning of nuanced frames for analyzing polarization in news media,2020,,,arXiv preprint arXiv:2009.09609,,,,,"Roy, Shamik and Goldwasser, Dan",,,,,,included,,Learning,,
rayyan-1120387431,Creating a dataset for fine-grained bias detection in news articles - Forum on Data Engineering and Information Management - Forum on Data Engineering and Information Management,2020,,,,,12,,1--35,"Lim, Sora and Jatowt, Adam and Masatoshi, Y",,,,,,included,,Bias (Epidemiology);Cereals,,
rayyan-1120387432,"Multi-modal analysis of misleading political news - Disinformation in Open Online Media: Second Multidisciplinary International Symposium, MISDOOM 2020, Leiden, The Netherlands, October 26--27, 2020, Proceedings 2 - Disinformation in Open Online Media: Second Multidisciplinary International Symposium, MISDOOM 2020, Leiden, The Netherlands, October 26--27, 2020, Proceedings 2",2020,,,,,,,261--276,"Shrestha, Anu and Spezzano, Francesca and Gurunathan, Indhumathi",,,,,,other_method,,Netherlands,,
rayyan-1120387433,Judging a Book By Its Cover: Predicting Partisanship Using Only Article Titles,2019,,,Text Analysis and Retrieval 2019 Course Project Reports,,,,40,"Liskij, Mihael and Prester, Dominik and {\v{S}}ego, Ivan",,,,,,not_pertinent_document,,,,
rayyan-1120387434,Team Harry Friberg at SemEval-2019 Task 4: Identifying Hyperpartisan News through Editorially Defined Metatopics - Proceedings of the 13th International Workshop on Semantic Evaluation - Proceedings of the 13th International Workshop on Semantic Evaluation,2019,,,,,,,1004--1006,"Afsarmanesh, Nazanin and Karlgren, Jussi and Sumbler, Peter and Viereckel, Nina",,,,,,included,,Semantics,,
rayyan-1120387435,HoaxItaly: a collection of Italian disinformation and fact-checking stories shared on Twitter in 2019,2020,,,arXiv preprint arXiv:2001.10926,,,,,"Pierri, Francesco and Artoni, Aless and ro and Ceri, Stefano",,,,,,included,,,,
rayyan-1120387436,An Automated News Bias Classifier Using Caenorhabditis Elegans Inspired Recursive Feedback Network Architecture,2022,,,arXiv preprint arXiv:2207.12724,,,,,"Sridharan, Agastya and others",,,,,,included,,Feedback;Bias (Epidemiology),,
rayyan-1120387437,POLITICS: pretraining with same-story article comparison for ideology prediction and stance detection,2022,,,arXiv preprint arXiv:2205.00619,,,,,"Liu, Yujian and Zhang, Xinliang Frederick and Wegsman, David and Beauchamp, Nick and Wang, Lu",,,,,,included,,,,
rayyan-1120387438,Duluth at SemEval-2019 Task 4: The Pioquinto Manterola Hyperpartisan News Detector - Proceedings of the 13th International Workshop on Semantic Evaluation - Proceedings of the 13th International Workshop on Semantic Evaluation,2019,,,,,,,949--953,"Sengupta, Saptarshi and Pedersen, Ted",,,,,,included,,Semantics,,
rayyan-1120387439,NELA-GT-2018: A large multi-labelled news dataset for the study of misinformation in news articles - Proceedings of the international AAAI conference on web and social media - Proceedings of the international AAAI conference on web and social media,2019,,,,,13,,630--638,"N{\o}rregaard, Jeppe and Horne, Benjamin D and Adal{\i}, Sibel",,,,,,included,,,,
rayyan-1120387440,Frank at checkthat! 2023: Detecting the political bias of news articles and news media,2023,,,Working Notes of CLEF,,,,,"Azizov, Dilshod and Liang, S and Nakov, P",,,,,,included,,Bias (Epidemiology),,
rayyan-1120387441,"On sentence representations for propaganda detection: From handcrafted features to word embeddings - Proceedings of the Second Workshop on Natural Language Processing for Internet Freedom: Censorship, Disinformation, and Propaganda - Proceedings of the Second Workshop on Natural Language Processing for Internet Freedom: Censorship, Disinformation, and Propaganda",2019,,,,,,,107--112,"Cruz, Andr{\'e} Ferreira and Rocha, Gil and Cardoso, Henrique Lopes",,,,,,other_task,,Propaganda;Internet,,
rayyan-1120387442,Detecting Political Bias in Speeches and News Articles Final Report,,,,,,,,,"Angle, Sachi and Tech, Cornell and Ganesh, Varun and Gheissari, Pargol and Schiller, Rina and Sempere, Nicolas",,,,,,not_pertinent_document,,Bias (Epidemiology);Speech,,
rayyan-1120387443,Amfb: Attention based multimodal factorized bilinear pooling for multimodal fake news detection,2021,,,Expert Systems with Applications,,184,,115412,"Kumari, Rina and Ekbal, Asif",,,Elsevier,,,other_task,,,,
rayyan-1120387444,Multimodal Approaches based on Fake News Detection - 2023 Third International Conference on Artificial Intelligence and Smart Energy (ICAIS) - 2023 Third International Conference on Artificial Intelligence and Smart Energy (ICAIS),2023,,,,,,,751--755,"Reddy, B and i Sravani and Kumar, AP Siva",,,,,,other_method,,Intelligence,,
rayyan-1120387445,Overview of the CLEF-2023 CheckThat! lab task 3 on political bias of news articles and news media,2023,,,Working Notes of CLEF,,,,,"Da San Martino, Giovanni and Alam, Firoj and Hasanain, Maram and N and i, Rabindra Nath and Azizov, Dilshod and Nakov, Preslav",,,,,,not_pertinent_document,,Bias (Epidemiology),,
rayyan-1120387446,Publishers/sources (Disinformation),2021,,,DOCA-Database of Variables for Content Analysis,,,,,"Staender, Anna and Humprecht, Edda",,,,,,not_pertinent,,,,
rayyan-1120387447,Role of ELMo Embedding in Detecting Fake News on Social Media - 2022 11th International Conference on System Modeling \& Advancement in Research Trends (SMART) - 2022 11th International Conference on System Modeling \& Advancement in Research Trends (SMART),2022,,,,,,,57--60,"Garg, Sonal and Sharma, Dilip Kumar",,,,,,included,,,,
rayyan-1120387448,Topic-based Models with Fact Checking for Fake News Identification. - RoCHI - RoCHI,2022,,,,,,,1--5,"Devi, T and Jaisharma, K and Deepa, N",,,,,,other_task,,Neural Networks (Computer);Nerve Net;Intelligence,,
rayyan-1120387449,Writer movements between news outlets reflect political polarization in media,2023,,,new media \& society,,25,8,2034--2056,"Hagar, Nick and Wachs, Johannes and Horv{\'a}t, Em{\H{o}}ke-{\'A}gnes",,,"SAGE Publications Sage UK: London, England",,,not_pertinent,,Movement,,
rayyan-1120387450,Understanding Political Polarisation using Language Models: A dataset and method,2023,,,arXiv preprint arXiv:2301.00891,,,,,"Gode, Samiran and Bare, Supreeth and Raj, Bhiksha and Yoo, Hyungon",,,,,,not_pertinent_document,,,,
rayyan-1120387451,Topic-based Models with Fact Checking for Fake News Identification. - RoCHI - RoCHI,2021,,,,,,,182--190,"Dumitru, Vlad Cristian and Rebedea, Traian",,,,,,included,,,,
rayyan-1120387452,Assessing Italian disinformation spread on Twitter during the 2019 European elections,2019,,,,,,,,"Artoni, Aless and ro",,,Italy,,,not_pertinent_data,,,,
rayyan-1120387453,How biased are American media outlets? A framework for presentation bias regression,2020,,,"Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",,,,4359-4364,"Tran, M.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103814921&doi=10.1109%2fBigData50022.2020.9377987&partnerID=40&md5=e1fe4b87888e4ff379f1901fe3d514ec,,,,"Media bias is a pressing issue in our society that can increase political polarization. To address the issue, previous studies mainly develop supervised learning models to identify bias at the article level, which not only requires expensive data collection but also careful features selection. An alternative approach to combat media bias focuses on the source level, which can help news aggregators promptly filter unreliable news based on their sources. Despite being a promising approach, the detection of biases at the source level remains largely unexplored. In this study, we propose a novel unsupervised framework to estimate presentation bias of news sources. The framework first uses a retrieval engine to form groups of related articles, then constructs pairwise biases between news sources using Aspect-based Sentiment Analysis (ABSA) and finally, assigns bias scores for each source with a graph-based algorithm. Using a dataset of approximately 83K articles from 14 news sources, we validate the results of our framework with 3 benchmarks and find that our approach can provide reliable bias ratings, with a Pearson correlation coefficient of up to 0.92. We further discuss the possibility of extending the framework to identify selection bias. © 2020 IEEE.",included,10.1109/BigData50022.2020.9377987,media bias;politics;sentiment analysis;Correlation methods;Graph algorithms;Graphic methods;Sentiment analysis;Data collection;Features selection;Graph-based algorithms;News aggregators;Pearson correlation coefficients;Presentation bias;Retrieval engines;Selection bias;Big data;Bias (Epidemiology),,
rayyan-1120387454,UPB at SemEval-2020 Task 11: Propaganda Detection with Domain-Specific Trained BERT,2020,,,"14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings",,,,1853-1857,"Paraschiv, A. and Cercel, D.-C. and Dascalu, M.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106134200&partnerID=40&md5=34a05bbbba293c797cd48e4f9ea51963,,,,"Manipulative and misleading news have become a commodity for some online news outlets and these news have gained a significant impact on the global mindset of people. Propaganda is a frequently employed manipulation method having as goal to influence readers by spreading ideas meant to distort or manipulate their opinions. This paper describes our participation in the SemEval-2020, Task 11: Detection of Propaganda Techniques in News Articles competition. Our approach considers specializing a pre-trained BERT model on propagandistic and hyperpartisan news articles, enabling it to create more adequate representations for the two subtasks, namely propaganda Span Identification (SI) and propaganda Technique Classification (TC). Our proposed system achieved a F1-score of 46.060% in subtask SI, ranking 5th in the leaderboard from 36 teams and a micro-averaged F1 score of 54.302% for subtask TC, ranking 19th from 32 teams. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.",other_task,,Classification (of information);Computational linguistics;Domain specific;F1 scores;Manipulation methods;News articles;Online news;Subtask;Semantics;Propaganda,,
rayyan-1120387455,UBC-NLP at SemEval-2019 task 4: Hyperpartisan news detection with attention-based Bi-LSTMs,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1072-1077,"Zhang, C. and Rajendran, A. and Abdul-Mageed, M.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118595407&partnerID=40&md5=8389fc6fe1a41ad41279d7e33b7503a3,,,,"We present our deep learning models submitted to the SemEval-2019 Task 4 competition focused at Hyperpartisan News Detection. We acquire best results with a Bi-LSTM network equipped with a self-attention mechanism. Among 33 participating teams, our submitted system ranks top 7 (65.3% accuracy) on the labels-by-publisher sub-task and top 24 out of 44 teams (68.3% accuracy) on the labels-by-article sub-task (65.3% accuracy). We also report a model that scores higher than the 8th ranking system (78.5% accuracy) on the labels-by-article sub-task. © 2019 Association for Computational Linguistics",included,,Semantics;Attention mechanisms;Learning models;Participating teams;Ranking system;Subtask;Long short-term memory,,
rayyan-1120387457,A stylometric inquiry into hyperpartisan and fake news,2018,,,"ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)",,1,,231-240,"Potthast, M. and Kiesel, J. and Reinartz, K. and Bevendorff, J. and Stein, B.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063109511&doi=10.18653%2fv1%2fp18-1022&partnerID=40&md5=6799a33d249157cc3a119ea9a609e9c3,,,,"We report on a comparative style analysis of hyperpartisan (extremely one-sided) news and fake news. A corpus of 1,627 articles from 9 political publishers, three each from the mainstream, the hyperpartisan left, and the hyperpartisan right, have been fact-checked by professional journalists at BuzzFeed: 97% of the 299 fake news articles identified are also hyperpartisan. We show how a style analysis can distinguish hyperpartisan news from the mainstream (F1 = 0.78), and satire from both (F1 = 0.81). But stylometry is no silver bullet as style-based fake news detection does not work (F1 = 0.46). We further reveal that left-wing and right-wing news share significantly more stylistic similarities than either does with the mainstream. This result is robust: it has been confirmed by three different modeling approaches, one of which employs Unmasking in a novel way. Applications of our results include partisanship detection and pre-screening for semi-automatic fake news detection. © 2018 Association for Computational Linguistics",included,10.18653/v1/p18-1022,Model approach;News articles;Semi-automatics;Stylistic similarity;Stylometry;Computational linguistics,,
rayyan-1120387458,Masking and Transformer-based Models for Hyperpartisanship Detection in News,2021,,,"International Conference Recent Advances in Natural Language Processing, RANLP",,,,1244-1251,"Sánchez-Junquera, J. and Rosso, P. and Montes-Y-Gómez, M. and Ponzetto, S.P.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123606605&doi=10.26615%2f978-954-452-072-4_140&partnerID=40&md5=04404f1d0eb3e05f7c77dd6f7ca3e562,,,,"Hyperpartisan news show an extreme manipulation of reality based on an underlying and extreme ideological orientation. Because of its harmful effects at reinforcing one's bias and the posterior behavior of people, hyperpartisan news detection has become an important task for computational linguists. In this paper, we evaluate two different approaches to detect hyperpartisan news. First, a text masking technique that allows us to compare style vs. topic-related features in a different perspective from previous work. Second, the transformer-based models BERT, XLM-RoBERTa, and M-BERT, known for their ability to capture semantic and syntactic patterns in the same representation. Our results corroborate previous research on this task in that topic-related features yield better results than style-based ones, although they also highlight the relevance of using higher-length n-grams. Furthermore, they show that transformer-based models are more effective than traditional methods, but this at the cost of greater computational complexity and lack of transparency. Based on our experiments, we conclude that the beginning of the news show relevant information for the transformers at distinguishing effectively between left-wing, mainstream, and right-wing orientations. © 2021 Incoma Ltd. All rights reserved.",included,10.26615/978-954-452-072-4_140,Harmful effects;Masking technique;N-grams;Semantic pattern;Syntactic patterns;Semantics,,
rayyan-1120387459,Creation of Polish Online News Corpus for Political Polarization Studies,2022,,,"1st Workshop on Natural Language Processing for Political Sciences, PoliticalNLP 2022 - Proceedings, as part of the 13th Edition of the Language Resources and Evaluation Conference, LREC 2022",,,,86-90,"Szwoch, J. and Staszkow, M. and Rzepka, R. and Araki, K.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145964536&partnerID=40&md5=e4f8bb02d0beedb8627f147acf8a9720,,,,"In this paper we describe a Polish news corpus as an attempt to create a filtered, organized and representative set of texts coming from contemporary online press articles from two major Polish TV news providers: commercial TVN24 and state-owned TVP Info. The process consists of web scraping, data cleaning and formatting. A random sample was selected from prepared data to perform a classification task. The random forest achieved the best prediction results out of all considered models. We believe that this dataset is a valuable contribution to existing Polish language corpora as online news are considered to be formal and relatively mistake-free, therefore, a reliable source of correct written language, unlike other online platforms such as blogs or social media. Furthermore, to our knowledge, such corpus from this period of time has not been created before. In the future we would like to expand this dataset with articles coming from other online news providers, repeat the classification task on a bigger scale, utilizing other algorithms. Our data analysis outcomes might be a relevant basis to improve research on a political polarization and propaganda techniques in media. © 2022 European Language Resources Association (ELRA).",included,,classification;news corpus;NLP;Polish language;web scraping;Polarization;Classification tasks;Data cleaning;Data formatting;News corpora;Online news;Polarization study;Random sample;TV news;Web scrapings;Classification (of information),,
rayyan-1120387460,Spider-Jerusalem at SemEval-2019 task 4: Hyperpartisan news detection,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,985-989,"Alabdulkarim, A. and Alhindi, T.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118544610&partnerID=40&md5=8c3cce1f0b3e6417819a2ab570794c18,,,,"This paper describes our system for detecting hyperpartisan news articles, which was submitted for the shared task in SemEval 2019 on Hyperpartisan News Detection. We developed a Support Vector Machine (SVM) model that uses TF-IDF of tokens, Language Inquiry and Word Count (LIWC) features, and structural features such as number of paragraphs and hyperlink count in an article. The model was trained on 645 articles from two classes: mainstream and hyperpartisan. Our system was ranked seventeenth out of forty two participating teams in the binary classification task with an accuracy score of 0.742 on the blind test set (the accuracy of the top ranked system was 0.822). We provide a detailed description of our preprocessing steps, discussion of our experiments using different combinations of features, and analysis of our results and prediction errors. © 2019 Association for Computational Linguistics",included,,Classification (of information);Semantics;Support vector machines;As numbers;Binary classification;Blind test;Classification tasks;Hyperlinks;Jerusalem;News articles;Participating teams;Structural feature;Support vector machine models;Hypertext systems,,
rayyan-1120387461,On the detection of political and social bias,2021,,,CEUR Workshop Proceedings,,3030,,41-49,"Sánchez-Junquera, J.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121306424&partnerID=40&md5=84240c3707c4db38c5c7b6603f35770c,,,,"Nowadays it is very easy to share, create and disseminate any kind of bias thanks to the increasing facilities of the technology. Political and social bias have a lamentable repercussion on the behaviours of people and our life quality. This research is focused on the detection of hyperpartisan news and immigrant stereotypes in political speeches. This work proposes two different explainable approaches: BERT-based models, known for their ability to capture semantic and syntactic patterns in the same representation but at the cost of great computational complexity and lack of transparency; and a masking-based model that has been recognized by its capabilities to deliver good and human-understandable results. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",included,,BERT-based models;Hyperpartisan news;Immigrant stereotypes;Masking technique;Political bias;Social bias;BERT-based model;Immigrant stereotype;Life qualities;Semantic pattern;Syntactic patterns;Semantics;Bias (Epidemiology),,
rayyan-1120387462,Team Ned Leeds at SemEval-2019 task 4: Exploring language indicators of hyperpartisan reporting,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1026-1031,"Stevanoski, B. and Gievska, S.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118597392&partnerID=40&md5=4ec7b35e9dafe8fc5b77cbac765a8015,,,,"This paper reports an experiment carried out to investigate the relevance of several syntactic, stylistic and pragmatic features on the task of distinguishing between mainstream and partisan news articles. The results of the evaluation of different feature sets and the extent to which various feature categories could affect the performance metrics are discussed and compared. Among different combinations of features and classifiers, Random Forest classifier using vector representations of the headline and the text of the report, with the inclusion of 8 readability scores and few stylistic features yielded best result, ranking our team at the 9th place at the SemEval 2019 Hyperpartisan News Detection challenge. © 2019 Association for Computational Linguistics",included,,Classification (of information);Semantics;Features sets;News articles;Performance metrices;Random forest classifier;Vector representations;Decision trees,,
rayyan-1120387463,Harvey Mudd College at SemEval-2019 task 4: The D.X. Beaumont hyperpartisan news detector,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,967-970,"Amason, E. and Palanker, J. and Shen, M.C. and Medero, J.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118529322&partnerID=40&md5=ff09ac4eb314852822d067d59b1f96cf,,,,"We use the 600 hand-labelled articles from SemEval Task 4 (Kiesel et al., 2019) to hand-tune a classifier with 3000 features for the Hyperpartisan News Detection task. Our final system uses features based on bag-of-words (BoW), analysis of the article title, language complexity, and simple sentiment analysis in a naive Bayes classifier. We trained our final system on the 600,000 articles labelled by publisher. Our final system has an accuracy of 0.653 on the hand-labeled test set. The most effective features are the Automated Readability Index and the presence of certain words in the title. This suggests that hyperpartisan writing uses a distinct writing style, especially in the title. © 2019 Association for Computational Linguistics",included,,Classifiers;Semantics;Bag of words;Detection tasks;Feature-based;Harvey mudd colleges;Language complexity;Naive Bayes classifiers;Sentiment analysis;Simple++;System use;Test sets,,
rayyan-1120387464,SemEval-2019 task 4: Hyperpartisan news detection,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,829-839,"Kiesel, J. and Mestre, M. and Shukla, R. and Vincent, E. and Adineh, P. and Corney, D. and Stein, B. and Potthast, M.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083032765&partnerID=40&md5=993158caf116bbfa0006806a44b7f665,,,,"Hyperpartisan news is news that takes an extreme left-wing or right-wing standpoint. If one is able to reliably compute this meta information, news articles may be automatically tagged, this way encouraging or discouraging readers to consume the text. It is an open question how successfully hyperpartisan news detection can be automated, and the goal of this SemEval task was to shed light on the state of the art. We developed new resources for this purpose, including a manually labeled dataset with 1,273 articles, and a second dataset with 754,000 articles, labeled via distant supervision. The interest of the research community in our task exceeded all our expectations: The datasets were downloaded about 1,000 times, 322 teams registered, of which 184 configured a virtual machine on our shared task cloud service TIRA, of which in turn 42 teams submitted a valid run. The best team achieved an accuracy of 0.822 on a balanced sample (yes: no hyperpartisan) drawn from the manually tagged corpus; an ensemble of the submitted systems increased the accuracy by 0.048. © 2019 Association for Computational Linguistics",included,,Cloud services;Labeled dataset;Meta information;News articles;Research communities;State of the art,,
rayyan-1120387465,Hyperpartisan news classification with elmo and bias feature,2021,,,Journal of Information Science and Engineering,,37,5,1177-1186,"HUANG, G.K.W. and LEE, J.C.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115976124&doi=10.6688%2fJISE.202109_37%285%29.0013&partnerID=40&md5=6d58a84e596c28218913a9921679c096,,,,"Hyperpartisan news is a kind of news riddled with twisted, untruthful, and often extremely one-sided. This kind of news can spread more successfully than the others. One of the obvious traits of hyperpartisan news content is that it can mimic regular news articles. Most are favour fake news detection algorithms, and there is less research conducted for hyperpartisan news. This research aims to perform classification on the hyperpartisan news using ELMo and bias features. ELMo was used to develop a classification model to perform classification on the BuzzFeed Webis News Corpus dataset. The model uses ELMo embedding with bias word score generated from bias lexicon to train a deep learning model using Tensorflow and Keras. We had compared the final result with two proposed baseline models that utilized ELMo from other research. The discussion section further investigated the contribution of ELMo and bias feature in the hyperpartisan task. © 2021 Institute of Information Science. All rights reserved.",included,10.6688/JISE.202109_37(5).0013,Bias detection;Classification;ELMo;Hyperpartisan;Natural language processing;Classification (of information);Deep learning;Classification models;Detection algorithm;Embeddings;Model use;News articles;News content;News corpora;Natural language processing systems;Bias (Epidemiology),,
rayyan-1120387466,Team Kit Kittredge at SemEval-2019 task 4: LSTM voting system,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1021-1025,"Cramerus, R. and Scheffler, T.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118569817&partnerID=40&md5=8594c7fda8fa9c964375e943fb424b42,,,,"This paper describes the approach of team Kit Kittredge to SemEval 2019 Task 4: Hyperpartisan News Detection. The goal was binary classification of news articles into the categories of “biased” or “unbiased”. We had two software submissions: one a simple bag-of-words model, and the second an LSTM (Long Short Term Memory) neural network, which was trained on a subset of the original dataset selected by a voting system of other LSTMs. This method did not prove much more successful than the baseline, however, due to the models' tendency to learn publisher-specific traits instead of general bias. © 2019 Association for Computational Linguistics",included,,Computational linguistics;Information retrieval;Semantics;Bag-of-words models;Binary classification;Learn+;Neural-networks;News articles;Simple++;Voting systems;Long short-term memory,,
rayyan-1120387467,Team Peter-Parker at SemEval-2019 task 4: BERT-based method in hyperpartisan news detection,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1037-1040,"Ning, Z. and Lin, Y. and Zhong, R.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118576507&partnerID=40&md5=b1a3ac34fc402876a1adde2c45b00f2c,,,,"This paper describes the team peter-parker's participation in Hyperpartisan News Detection task (SemEval-2019 Task 4), which requires to classify whether a given news article is bias or not. We decided to use Java to do the article parser and the BERT model to do the bias analysis and prediction. Furthermore, we will show experiment results with analysis. © 2019 Association for Computational Linguistics",included,,Detection tasks;News articles,,
rayyan-1120387468,Fermi at SemEval-2019 task 4: The Sarah-Jane-Smith Hyperpartisan news detector,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,954-956,"Chakravartula, N. and Indurthi, V. and Syed, B.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118549369&partnerID=40&md5=bc430fef2bd24f0bc3274ebac2bc2374,,,,"This paper describes our system (Fermi) for Task 4: Hyper-partisan News detection of SemEval-2019. We use simple text classification algorithms by transforming the input features to a reduced feature set. We aim to find the right number of features useful for efficient classification and explore multiple training models to evaluate the performance of these text classification algorithms. Our team - Fermi's model achieved an accuracy of 59.10% and an F1 score of 69.5% on the official test data set. In this paper, we provide a detailed description of the approach as well as the results obtained in the task. © 2019 Association for Computational Linguistics",included,,Classification (of information);Computational linguistics;Semantics;Statistical tests;Data set;F1 scores;Features sets;Input features;Performance;Simple++;Test data;Training model;Text processing,,
rayyan-1120387469,Harvey Mudd College at SemEval-2019 task 4: The Carl Kolchak Hyperpartisan News Detector,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,957-961,"Chen, C. and Park, C. and Dwyer, J. and Medero, J.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118530519&partnerID=40&md5=b7f94db5e352cc4f216cdb6d1440b9cb,,,,"We use various natural processing and machine learning methods to perform the Hyperpartisan News Detection task. In particular, some of the features we look at are bag-of-words features, the title's length, number of capitalized words in the title, and the sentiment of the sentences and the title. By adding these features, we see improvements in our evaluation metrics compared to the baseline values. We find that sentiment analysis helps improve our evaluation metrics. We do not see a benefit from feature selection. Overall, our system achieves an accuracy of 0.739, finishing 18th out of 42 submissions to the task. From our work, it is evident that both title features and sentiment of articles are meaningful to the hyperpartisanship of news articles. © 2019 Association for Computational Linguistics",included,,Computational linguistics;Learning systems;Semantics;Bag of words;Baseline values;Detection tasks;Evaluation metrics;Features selection;Harvey mudd colleges;Machine learning methods;News articles;Sentiment analysis,,
rayyan-1120387470,Rouletabille at SemEval-2019 task 4: Neural network baseline for identification of hyperpartisan publishers,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,981-984,"Moreno, J.G. and Pitarch, Y. and Pinel-Sauvagnat, K. and Hubert, G.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101432037&partnerID=40&md5=cd0ca33281546952d20f2732f7e9866b,,,,This paper describes the Rouletabille participation to the Hyperpartisan News Detection task. We propose the use of different text classification methods for this task. Preliminary experiments using a similar collection used in Potthast et al. (2018) show that neural-based classification methods reach state-of-the art results. Our final submission is composed of a unique run that ranks among all runs at 3/49 position for the by-publisher test dataset and 43/96 for the by-article test dataset in terms of Accuracy. © 2019 Association for Computational Linguistics,included,,Computational linguistics;Semantics;Statistical tests;Text processing;Classification methods;Detection tasks;Neural-networks;State of the art;Text classification methods;Classification (of information);Nerve Net;Neural Networks (Computer),,
rayyan-1120387471,Team yeon-zi at SemEval-2019 task 4: Hyperpartisan news detection by de-noising weakly-labeled data,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1052-1056,"Lee, N. and Liu, Z. and Fung, P.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084291759&partnerID=40&md5=fa18afb8000e94fb45b1a9b40b516b1d,,,,This paper describes our system submitted to SemEval-2019 Task 4: Hyperpartisan News Detection. We focus on removing the inherent noise in the hyperpartisanship dataset from both data-level and model-level by leveraging semi-supervised pseudo-labels and the state-of-the-art BERT model. Our model achieves 75.8% accuracy in the final by-article dataset without ensemble learning. © 2019 Association for Computational Linguistics,included,,Data level;De-noising;Ensemble learning;Inherent noise;Labeled data;Semi-supervised;State of the art,,
rayyan-1120387472,Harvey Mudd College at SemEval-2019 task 4: The Clint Buchanan hyperpartisan news detector,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,962-966,"Drissi, M. and S and oval, P. and Ojha, V. and Medero, J.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098818688&partnerID=40&md5=f0779f67d62bc0b5d0b22a787d0a1d01,,,,"We investigate the recently developed Bidirectional Encoder Representations from Transformers (BERT) model (Devlin et al., 2018) for the hyperpartisan news detection task. Using a subset of hand-labeled articles from SemEval as a validation set, we test the performance of different parameters for BERT models. We find that accuracy from two different BERT models using different proportions of the articles is consistently high, with our best-performing model on the validation set achieving 85% accuracy and the best-performing model on the test set achieving 77%. We further determined that our model exhibits strong consistency, labeling independent slices of the same article identically. Finally, we find that randomizing the order of word pieces dramatically reduces validation accuracy (to approximately 60%), but that shuffling groups of four or more word pieces maintains an accuracy of about 80%, indicating the model mainly gains value from local context. © 2019 Association for Computational Linguistics",included,,Detection tasks;Different proportions;Gain values;Harvey mudd colleges;Labelings;Performance;Strong consistency;Test sets;Transformer modeling;Validation sets,,
rayyan-1120387473,Fine-grained Classification of Political Bias in German News: A Data Set and Initial Experiments,2021,,,"WOAH 2021 - 5th Workshop on Online Abuse and Harms, Proceedings of the Workshop",,,,121-131,"Aksenov, D. and Bourgonje, P. and Zaczynska, K. and Ostendorff, M. and Moreno-Schneider, J. and Rehm, G.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130502864&partnerID=40&md5=a259aec1fd83912c76cf2e04942c0963,,,,"We present a data set consisting of German news articles labeled for political bias on a fivepoint scale in a semi-supervised way. While earlier work on hyperpartisan news detection uses binary classification (i. e., hyperpartisan or not) and English data, we argue for a more fine-grained classification, covering the full political spectrum (i. e., far-left, left, centre, right, far-right) and for extending research to German data. Understanding political bias helps in accurately detecting hate speech and online abuse. We experiment with different classification methods for political bias detection. Their comparatively low performance (a macro-F1 of 43 for our best setup, compared to a macro-F1 of 79 for the binary classification task) underlines the need for more (balanced) data annotated in a fine-grained way.  © 2021 Association for Computational Linguistics.",included,,Computational linguistics;Binary classification;Classification methods;Classification tasks;Data set;Fine grained;News articles;Performance;Semi-supervised;Spectra's;Classification (of information);Bias (Epidemiology);Cereals,,
rayyan-1120387474,Team JACK RYDER at SemEval-2019 task 4: Using BERT representations for detecting hyperpartisan news,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1012-1015,"Shaprin, D. and da San Martino, G. and Barrón-Cedeño, A. and Nakov, P.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095486893&partnerID=40&md5=d0478524c4a31e7ff3be8cffa96309e7,,,,"We describe the system submitted by the Jack Ryder team to SemEval-2019 Task 4 on Hyperpartisan News Detection. The task asked participants to predict whether a given article is hyperpartisan, i.e., extreme-left or extreme-right. We propose an approach based on BERT with fine-tuning, which was ranked 7th out 28 teams on the distantly supervised dataset, where all articles from a hyperpartisan/non-hyperpartisan news outlet are considered to be hyperpartisan/non-hyperpartisan. On a manually annotated test dataset, where human annotators double-checked the labels, we were ranked 29th out of 42 teams. © 2019 Association for Computational Linguistics",included,,Semantics;Fine tuning;Statistical tests,,
rayyan-1120387475,Tintin at SemEval-2019 task 4: Detecting hyperpartisan news article with only simple tokens,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1062-1066,"Bestgen, Y.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083036661&partnerID=40&md5=3c2bc6ecfa5d97d3a11ad1e05d98d6ec,,,,"Tintin, the system proposed by the CECL for the Hyperpartisan News Detection task of SemEval 2019, is exclusively based on the tokens that make up the documents and a standard supervised learning procedure. It obtained very contrasting results: poor on the main task, but much more effective at distinguishing documents published by hyperpartisan media outlets from unbiased ones, as it ranked first. An analysis of the most important features highlighted the positive aspects, but also some potential limitations of the approach. © 2019 Association for Computational Linguistics",included,,Detection tasks;Important features;Main tasks;Media outlets;News articles;Simple++,,
rayyan-1120387476,Multi-task ordinal regression for jointly predicting the trustworthiness and the leading political ideology of news media,2019,,,NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference,,1,,2109-2116,"Baly, R. and Karadzhov, G. and Saleh, A. and Glass, J. and Nakov, P.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070522837&partnerID=40&md5=732f03aa281017b2c5dfeba967a85a2a,,,,"In the context of fake news, bias, and propaganda, we study two important but relatively under-explored problems: (i) trustworthiness estimation (on a 3-point scale) and (ii) political ideology detection (left/right bias on a 7-point scale) of entire news outlets, as opposed to evaluating individual articles. In particular, we propose a multi-task ordinal regression framework that models the two problems jointly. This is motivated by the observation that hyper-partisanship is often linked to low trustworthiness, e.g., appealing to emotions rather than sticking to the facts, while center media tend to be generally more impartial and trustworthy. We further use several auxiliary tasks, modeling centrality, hyper-partisanship, as well as left-vs.-right bias on a coarse-grained scale. The evaluation results show sizable performance gains by the joint models over models that target the problems in isolation. © 2019 Association for Computational Linguistics",included,,Coarse-grained;Evaluation results;Joint models;News media;Ordinal regression;Performance Gain;Political ideologies;Computational linguistics,,
rayyan-1120387477,Team QCRI-MIT at SemEval-2019 task 4: Propaganda analysis meets hyperpartisan news detection,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1041-1046,"Saleh, A. and Baly, R. and Barrón-Cedeño, A. and da San Martino, G. and Mohtarami, M. and Nakov, P. and Glass, J.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118555311&partnerID=40&md5=e6047b63b2432068572d1a4a6b0e35db,,,,"We describe our submission to SemEval-2019 Task 4 on Hyperpartisan News Detection. We rely on a variety of engineered features originally used to detect propaganda. This is based on the assumption that biased messages are propagandistic and promote a particular political cause or viewpoint. In particular, we trained a logistic regression model with features ranging from simple bag of words to vocabulary richness and text readability. Our system achieved 72.9% accuracy on the manually annotated testset, and 60.8% on the test data that was obtained with distant supervision. Additional experiments showed that significant performance gains can be achieved with better feature pre-processing. © 2019 Association for Computational Linguistics",included,,Regression analysis;Additional experiments;Bag of words;Logistic Regression modeling;Performance Gain;Pre-processing;Simple++;Test data;Test sets;Semantics;Propaganda,,
rayyan-1120387478,Tom Jumbo-Grumbo at SemEval-2019 task 4: Hyperpartisan news detection with GloVe vectors and SVM,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1067-1071,"Yeh, C.-L. and Loni, B. and Schuth, A.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105932901&partnerID=40&md5=9b3672ba35eb7ad6c543bee5d8fb793e,,,,"In this paper, we describe our attempt to learn bias from news articles. From our experiments, it seems that although there is a correlation between publisher bias and article bias, it is challenging to learn bias directly from the publisher labels. On the other hand, using few manually-labeled samples can increase the accuracy metric from around 60% to near 80%. Our system is computationally inexpensive and uses several standard document representations in NLP to train an SVM or LR classifier. The system ranked 4th in the SemEval-2019 task. The code is released for reproducibility. © 2019 Association for Computational Linguistics",included,,Document Representation;Learn+;News articles;Reproducibilities;Standard documents,,
rayyan-1120387479,Quantitative and qualitative analysis of linking patterns of mainstream and partisan online news media in Central Europe,2022,,,Online Information Review,,46,5,954-973,"Hrckova, A. and Moro, R. and Srba, I. and Bielikova, M.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120500826&doi=10.1108%2fOIR-10-2020-0441&partnerID=40&md5=889344e80a6e4cd183367bbbc3555264,,,,"Purpose: Partisan news media, which often publish extremely biased, one-sided or even false news, are gaining popularity world-wide and represent a major societal issue. Due to a growing number of such media, a need for automatic detection approaches is of high demand. Automatic detection relies on various indicators (e.g. content characteristics) to identify new partisan media candidates and to predict their level of partisanship. The aim of the research is to investigate to a deeper extent whether it would be appropriate to rely on the hyperlinks as possible indicators for better automatic partisan news media detection. Design/methodology/approach: The authors utilized hyperlink network analysis to study the hyperlinks of partisan and mainstream media. The dataset involved the hyperlinks of 18 mainstream media and 15 partisan media in Slovakia and Czech Republic. More than 171 million domain pairs of inbound and outbound hyperlinks of selected online news media were collected with Ahrefs tool, analyzed and visualized with Gephi software. Additionally, 300 articles covering COVID-19 from both types of media were selected for content analysis of hyperlinks to verify the reliability of quantitative analysis and to provide more detailed analysis. Findings: The authors conclude that hyperlinks are reliable indicators of media affinity and linking patterns could contribute to partisan news detection. The authors found out that especially the incoming links with dofollow attribute to news websites are reliable indicators for assessing the type of media, as partisan media rarely receive links with dofollow attribute from mainstream media. The outgoing links are not such reliable indicators as both mainstream and partisan media link to mainstream sources similarly. Originality/value: In contrast to the extensive amount of research aiming at fake news detection within a piece of text or multimedia content (e.g. news articles, social media posts), the authors shift to characterization of the whole news media. In addition, the authors did a geographical shift from more researched US-based media to so far under-researched European context, particularly Central Europe. The results and conclusions can serve as a guide how to derive new features for an automatic detection of possibly partisan news media by means of artificial intelligence (AI). Peer review: The peer review history for this article is available at the following link: https://publons.com/publon/10.1108/OIR-10-2020-0441. © 2021, Emerald Publishing Limited.",other_method,10.1108/OIR-10-2020-0441,Central Europe;Content analysis;COVID-19;Hyperlink network analysis;Media profiling;Partisan online news media;Reliability analysis;Websites;Hyperlink network analyse;Hyperlink networks;Hyperlinks;Medium profiling;News media;Online news;Partisan online news medium;Hypertext systems;Europe,,
rayyan-1120387480,Narrative origin classification of israeli-palestinian conflict texts,2020,,,"Proceedings of the 33rd International Florida Artificial Intelligence Research Society Conference, FLAIRS 2020",,,,258-263,"Wei, J. and Santos, E.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102414297&partnerID=40&md5=340043873bcba078cc470ad7d1315a2e,,,,"The Israeli-Palestinian conflict is one of the most controversial in history. Not surprisingly, historic and contemporary literature on the topic tends to be polarized. Drawing inspiration from work in political ideology and hyperpartisan news detection, we collect two new datasets of history book excerpts and newspaper articles regarding the Israeli-Palestinian conflict and train sequence classifiers to predict whether a text is written by an Israeli or Palestinian source. Moreover, we find that data augmentation techniques improve performance, allowing our best model to detect narrative origin with an F1 score of 85.1% for history book excerpts and 91.9% for newspaper articles. Analysis of indicative phrases discovered by our models corroborate historian insight regarding the conflict. © FLAIRS 2020.All right reserved.",not_pertinent,,Classification (of information);History;Newsprint;Best model;Data augmentation;F1 scores;History books;Improve performance;Political ideologies;Artificial intelligence;Arabs,,
rayyan-1120387481,"Politicians-based Deep Learning Models for Detecting News, Authors and Media Political Ideology",2022,,,International Journal of Advanced Computer Science and Applications,,13,2,731-742,"Alzhrani, K.M.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126124032&doi=10.14569%2fIJACSA.2022.0130286&partnerID=40&md5=18a358767549869172a169db55b9e8e4,,,,"Non-partisanship is one of the qualities that contribute to journalistic objectivity. Factual reporting alone cannot combat political polarization in the news media. News framing, agenda settings, and priming are influence mechanisms that lead to political polarization, but they are hard to identify. This paper attempts to automate the detection of two political science concepts in news coverage: politician personalization and political ideology. Politicians’ news coverage personalization is a concept that encompasses one more of the influence mechanisms. Political ideologies are often associated with controversial topics such as abortion and health insurance. However, the paper prove that politicians’ personalization is related to the political ideology of the news articles. Constructing deep neural network models based on politicians’ personalization improved the performance of political ideology detection models. Also, deep networks models could predict news articles’ politician personalization with a high F1 score. Despite being trained on less data, personalizedbased deep networks proved to be more capable of capturing the ideology of news articles than other non-personalized models. The dataset consists of two politician personalization labels, namely Obama and Trump, and two political ideology labels, Democrat and Republican. The results showed that politicians’ personalization and political polarization exist in news articles, authors, and media sources. © 2022, (IJACSA) International Journal of Advanced Computer Science and Applications. All Rights Reserved.",other_task,10.14569/IJACSA.2022.0130286,Deep neural networks;Political ideology;Politician personalization;Text classification;Classification (of information);Health insurance;Polarization;Text processing;Agenda settings;Influence mechanism;Learning models;News articles;News coverage;News media;Personalizations;Political ideologies;Learning,,
rayyan-1120387482,Team Fernando-Pessa at SemEval-2019 task 4: Back to basics in hyperpartisan news detection,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,999-1003,"Cruz, A.F. and Rocha, G. and Sousa-Silva, R. and Cardoso, H.L.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083027921&partnerID=40&md5=dfab89edba9e37e598756c2f38e175eb,,,,"This paper describes our submission1 to the SemEval 2019 Hyperpartisan News Detection task. Our system aims for a linguistics-based document classification from a minimal set of interpretable features, while maintaining good performance. To this goal, we follow a feature-based approach and perform several experiments with different machine learning classifiers. On the main task, our model achieved an accuracy of 71.7%, which was improved after the task's end to 72.9%. We also participate in the meta-learning sub-task, for classifying documents with the binary classifications of all submitted systems as input, achieving an accuracy of 89.9%. © 2019 Association for Computational Linguistics",included,,Classification (of information);Information retrieval systems;Learning systems;Binary classification;Detection tasks;Document Classification;Feature based approaches;Main tasks;Metalearning;Performance;Subtask;Semantics,,
rayyan-1120387483,Team Bertha von Suttner at SemEval-2019 task 4: Hyperpartisan news detection using ELMo sentence representation convolutional network,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,840-844,"Jiang, Y. and Petrak, J. and Song, X. and Bontcheva, K. and Maynard, D.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083038399&partnerID=40&md5=2c5a784ba62023b6f7e6bf6a45b00dd0,,,,"This paper describes the participation of team “bertha-von-suttner” in the SemEval2019 task 4 Hyperpartisan News Detection task. Our system1 uses sentence representations from averaged word embeddings generated from the pre-trained ELMo model with Convolutional Neural Networks and Batch Normalization for predicting hyperpartisan news. The final predictions were generated from the averaged predictions of an ensemble of models. With this architecture, our system ranked in first place, based on accuracy, the official scoring metric. © 2019 Association for Computational Linguistics",included,,Convolution;Convolutional neural networks;Semantics;Convolutional networks;Convolutional neural network;Detection tasks;Embeddings;Ensemble of models;Normalisation;Place-based;Scoring metrics;Forecasting,,
rayyan-1120387484,On document representations for detection of biased news articles,2020,,,Proceedings of the ACM Symposium on Applied Computing,,,,892-899,"Cruz, A.F. and Rocha, G. and Cardoso, H.L.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083035044&doi=10.1145%2f3341105.3374025&partnerID=40&md5=f64dea3a63625a4d3f09d69eab03af8e,,,,"Detecting bias in text is an increasingly relevant topic, given the information overload problem. Automating this task is crucial for our needs of quality news consumption. With this in mind, we explore modern deep learning approaches, including contextualized word embeddings and attention mechanisms, to compare the effects of different document representation choices. We design token-wise, sentence-wise and hierarchical document representations. Focusing on hyperpartisan news detection, we show that hierarchical attention mechanisms are able to better capture information at different levels of granularity (including intra and inter-sentence), which seems to be relevant for this task. With an accuracy of 82.5%, our best performing system is based on an ensemble of hierarchical attention networks with ELMo embeddings, achieving state-of-the-art performance on the SemEval-2019 Task4 dataset. © 2020 ACM.",included,10.1145/3341105.3374025,Bias detection;Deep learning;Document representation;Hyperpartisan news;Natural language processing;Embeddings;Attention mechanisms;Document Representation;Hierarchical document;Information overloads;Learning approach;News articles;State-of-the-art performance;Bias (Epidemiology),,
rayyan-1120387485,The Sally Smedley Hyperpartisan News Detector at SemEval-2019 task 4: Learning classifiers with feature combinations and ensembling,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1057-1061,"Hanawa, K. and Sasaki, S. and Ouchi, H. and Suzuki, J. and Inui, K.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083038275&partnerID=40&md5=6210065e6a12aed9f8648389ad1882f8,,,,"This paper describes our system submitted to the formal run of SemEval-2019 Task 4: Hyperpartisan news detection. Our system is based on a linear classifier using several features, i.e., 1) embedding features based on the pre-trained BERT embeddings, 2) article length features, and 3) embedding features of informative phrases extracted from the by-publisher dataset. Our system achieved 80.9% accuracy on the test set for the formal run and got the 3rd place out of 42 teams. © 2019 Association for Computational Linguistics",included,,Classification (of information);Semantics;Embeddings;Feature combination;Feature-based;Learning classifiers;Linear classifiers;Test sets;Learning,,
rayyan-1120387486,Team Xenophilius Lovegood at SemEval-2019 task 4: Hyperpartisanship classification using convolutional neural networks,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1047-1051,"Zehe, A. and Hettinger, L. and Ernst, S. and Hauptmann, C. and Hotho, A.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118542511&partnerID=40&md5=77305c7005873282c45d5672f1075bd1,,,,"This paper describes our system for the SemEval 2019 Task 4 on hyperpartisan news detection. We build on an existing deep learning approach for sentence classification based on a Convolutional Neural Network. Modifying the original model with additional layers to increase its expressiveness and finally building an ensemble of multiple versions of the model, we obtain an accuracy of 67.52 % and an F1 score of 73.78 % on the main test dataset. We also report on additional experiments incorporating handcrafted features into the CNN and using it as a feature extractor for a linear SVM. © 2019 Association for Computational Linguistics",included,,Classification (of information);Convolutional neural networks;Deep learning;Semantics;Statistical tests;Support vector machines;Additional experiments;Convolutional neural network;F1 scores;Feature extractor;Learning approach;Linear SVM;Original model;Sentence classifications;Convolution;Nerve Net;Neural Networks (Computer),,
rayyan-1120387487,"Everyday non-partisan fake news: Sharing behavior, platform specificity, and detection",2023,,,Frontiers in Psychology,,14,,,"Shephard, M.P. and Robertson, D.J. and Huhe, N. and Anderson, A.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160808576&doi=10.3389%2ffpsyg.2023.1118407&partnerID=40&md5=82fc50b02694a57b8e23cf20fe6c48b7,,,,"Concern over the impact of fake news on major socio-political events is growing. The use of deliberate misinformation is thought to have played a role in the outcome of the UK EU referendum, the 2016 US presidential election, and in the effectiveness of COVID-19 public health messaging. As a result, recent research has tended to focus on hyper-partisan (e.g., US politics; Democrat/Republican), person specific (e.g., Hillary Clinton/Donald Trump) content that incorporates emotive and hyperbolic language. However, in this study, we focus on an alternative form of fake news, across a variety of topics (e.g., Crime, Immigration, and Health), that avoids these characteristics, and which may therefore be more pervasive and difficult to detect. In a three-part study, we examined participants sharing intentions for fake news (including platform preference; Facebook, Twitter, Instagram, and WhatsApp), their ability to explicitly detect fake news, and whether individual differences on psychological measures of critical thinking ability, rational thinking, and emotional stability predict sharing behavior and detection ability. The results show that even our well-informed sample (political science students) were not immune to the effects of fake news, some issues (e.g., health and crime) were more likely to be shared than others (e.g., immigration), and on specific platforms (e.g., Twitter, Facebook). In addition, we show that individual differences in emotional stability appears to be a key factor in sharing behavior, while rational thinking aptitude was key to fake news detection. Taken together, this study provides novel data that can be used to support targeted fake news interventions, suggesting possible news topic, sharing behavior, and platform specific insights. Such interventions, and implications for government policy, education, and social media companies are discussed. Copyright © 2023 Shephard, Robertson, Huhe and Anderson.",not_pertinent,10.3389/fpsyg.2023.1118407,fake news;individual differences;news sharing;news sharing platform;social media,,
rayyan-1120387488,Cardiff University at SemEval-2019 task 4: Linguistic features for hyperpartisan news detection,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,929-933,"Pérez-Almendros, C. and Espinosa-Anke, L. and Schockaert, S.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118590845&partnerID=40&md5=bfcf3b667c1a0ce14b433fceaa43017a,,,,"This paper summarizes our contribution to the Hyperpartisan News Detection task in SemEval 2019. We experiment with two different approaches: 1) an SVM classifier based on word vector averages and hand-crafted linguistic features, and 2) a BiLSTM-based neural text classifier trained on a filtered training set. Surprisingly, despite their different nature, both approaches achieve an accuracy of 0.74. The main focus of this paper is to further analyze the remarkable fact that a simple feature-based approach can perform on par with modern neural classifiers. We also highlight the effectiveness of our filtering strategy for training the neural network on a large but noisy training set. © 2019 Association for Computational Linguistics",included,,Classification (of information);Support vector machines;Cardiff;Detection tasks;Feature based approaches;Linguistic features;Neural classifiers;Simple++;SVM classifiers;Text classifiers;Training sets;Word vectors;Semantics,,
rayyan-1120387489,Fighting the Fake: A Forensic Linguistic Analysis to Fake News Detection,2022,,,International Journal for the Semiotics of Law,,35,6,2409-2433,"Sousa-Silva, R.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129037593&doi=10.1007%2fs11196-022-09901-w&partnerID=40&md5=85ed03a5e5aaf7acce3fe6c12b18be12,,,,"Fake news has been the focus of debate, especially since the election of Donald Trump (2016), and remains a topic of concern in democratic countries worldwide, given (a) their threat to democratic systems and (b) the difficulty in detecting them. Despite the deployment of sophisticated computational systems to identify fake news, as well as the streamlining of fact-checking methods, appropriate fake news detection mechanisms have not yet been found. In fact, technological approaches are likely to be inefficient, given that fake news are based mostly on partisanship and identity politics, and not necessarily on outright deception. However, as disinformation is inherently expressed linguistically, this is a privileged room for forensic linguistic analysis. This article builds upon a forensic linguistic analysis of fake news pieces published in English and in Portuguese, which were collected since 2019 from acknowledged fake news outlets. The preliminary empirical analysis reveals that fake news pieces employ particular linguistic features, e.g. at the levels of typography, orthography and spelling, and morphosyntax. The systematic identification of these features, which will allow mapping linguistic resources and patterns used in those contexts, contributes to scholarship, not only by enabling a streamlined development of computational detection systems, but more importantly by permitting the forensic linguistics expert to assist criminal investigations and give evidence in court. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.",other_task,10.1007/s11196-022-09901-w,Cybercrime;Disinformation;Fact-checking;Fake news;Forensic linguistics;Language crimes,,
rayyan-1120387490,Hyperpartisan news and articles detection using BERT and ELMo,2019,,,"Proceedings - 2019 International Conference on Computer and Drone Applications, IConDA 2019",,,,29-32,"Huang, G.K.W. and Lee, J.C.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083028514&doi=10.1109%2fIConDA47345.2019.9034917&partnerID=40&md5=18978bbc050794218fb0c0639a6337e1,,,,"Fake news and articles are misleading the readers. This leads to the increasing studies of fake news article detection over the decades. Hyperpartisan news is news riddled with twisted and untruth and extremely one-sided. This news can spread more successfully than others. Besides that, hyperpartisan news can mimic the form of regular news articles. This study aims to identify and classify the hyperpartisan news with BERT and ELMo. Two distinct models, BERT and ELMo, were created to classify hyperpartisan news from two datasets, namely by-article and by-publisher. Few other models with different settings and training designed to test and optimise the performance of both models. The results of the optimised BERT and ELMo models can achieve 68.4% and 60.8%, respectively. © 2019 IEEE.",included,10.1109/IConDA47345.2019.9034917,Classification;Hyperpartisan;Natural Language Processing;Drones;News articles;Classification (of information),,
rayyan-1120387491,Detection of hyperpartisan news articles using natural language processing technique,2022,,,International Journal of Information Management Data Insights,,2,1,,"Naredla, N.R. and Adedoyin, F.F.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126573366&doi=10.1016%2fj.jjimei.2022.100064&partnerID=40&md5=5b0c176890d3b6b85098b0602faaae6d,,,,"Yellow journalism has increased the spread of hyperpartisan news on the internet. It is very difficult for online news article readers to distinguish hyperpartisan news articles from mainstream news articles. There is a need for an automated model that can detect hyperpartisan news on the internet and tag them as hyperpartisan so that it is very easy for readers to avoid that news. A hyperpartisan news detection article was developed by using three different natural language processing techniques named BERT, ELMo, and Word2vec. This research used the bi-article dataset published at SEMEVAL-2019. The ELMo word embeddings which are trained on a Random forest classifier has got an accuracy of 0.88, which is much better than other state of art models. The BERT and Word2vec models have got the same accuracy of 0.83. This research tried different sentence input lengths to BERT and proved that BERT can extract context from local words. Evidenced from the described ML models, this study will assist the governments, news’ readers, and other political stakeholders to detect any hyperpartisan news, and also helps policy to track, and regulate, misinformation about the political parties and their leaders. © 2022 The Author(s)",included,10.1016/j.jjimei.2022.100064,BERT;Bidirectional;ELMo;NLP;Tensorflow;Transformers;Word embedding's;Word2vec,,
rayyan-1120387492,Brenda Starr at SemEval-2019 task 4: Hyperpartisan news detection,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,924-928,"Papadopoulou, O. and Kordopatis-Zilos, G. and Zampoglou, M. and Papadopoulos, S. and Kompatsiaris, Y.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118560616&partnerID=40&md5=357346b59dca19012dd09a1154d085a2,,,,"In the effort to tackle the challenge of Hyperpartisan News Detection, i.e., the task of deciding whether a news article is biased towards one party, faction, cause, or person, we experimented with two systems: i) a standard supervised learning approach using superficial text and bag-of-words features from the article title and body, and ii) a deep learning system comprising a four-layer convolutional neural network and max-pooling layers after the embedding layer, feeding the consolidated features to a bi-directional recurrent neural network. We achieved an F-score of 0.712 with our best approach, which corresponds to the mid-range of performance levels in the leaderboard. © 2019 Association for Computational Linguistics",included,,Computational linguistics;Multilayer neural networks;Network layers;Semantics;Bag of words;Bi-directional;Convolutional neural network;Embeddings;F-score;Max-pooling;News articles;Performance:level;Supervised learning approaches;Recurrent neural networks,,
rayyan-1120387493,Clark Kent at SemEval-2019 task 4: Stylometric insights into hyperpartisan news detection,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,934-938,"Gupta, V. and Jolly, B.L.K. and Kaur, R. and Chakraborty, T.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098824819&partnerID=40&md5=7d3c6151b2920b90dd0af6d50af3ee3a,,,,"In this paper, we present a news bias prediction system, which we developed as part of a SemEval 2019 task. We developed an XGBoost based system which uses character and word level n-gram features represented using TF-IDF, count vector based correlation matrix, and predicts if an input news article is a hyperpartisan news article. Our model was able to achieve a precision of 68.3% on the test set provided by the contest organizers. We also run our model on the BuzzFeed corpus and find XGBoost with simple character level N-Gram embeddings to be performing well with an accuracy of around 96%. © 2019 Association for Computational Linguistics",included,,Character level;Correlation matrix;Embeddings;N-grams;News articles;Prediction systems;Simple++;Stylometrics;Test sets;Word level;Semantics,,
rayyan-1120387494,Robust fake news detection over time and attack,2019,,,ACM Transactions on Intelligent Systems and Technology,,11,1,,"Horne, B.D. and NØrregaard, J. and Adali, S.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077367010&doi=10.1145%2f3363818&partnerID=40&md5=ff2c4901b28e59cc2cd1f7320e1086b7,,,,"In this study, we examine the impact of time on state-of-the-art news veracity classifiers. We show that, as time progresses, classification performance for both unreliable and hyper-partisan news classification slowly degrade. While this degradation does happen, it happens slower than expected, illustrating that hand-crafted, content-based features, such as style of writing, are fairly robust to changes in the news cycle.We show that this small degradation can bemitigated using online learning. Last, we examine the impact of adversarial content manipulation by malicious news producers. Specifically, we test three types of attack based on changes in the input space and data availability. We show that static models are susceptible to content manipulation attacks, but online models can recover from such attacks. © 2019 Association for Computing Machinery.",other_task,10.1145/3363818,Adversarial machine learning;Biased news;Concept drift;Disinformation;Fake news;Fake news detection;Misinformation;Misleading news;Robust machine learning;Concept drifts;Machine learning,,
rayyan-1120387495,Vernon-fenwick at SemEval-2019 task 4: Hyperpartisan news detection using lexical and semantic features,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1078-1082,"Srivastava, V. and Sahoo, S.K. and Gupta, A. and Rohit, R.R. and Prakash, D. and Kim, Y.H.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083026422&partnerID=40&md5=39507acd1bf13f2f9140016630c20edf,,,,"In this paper, we present our submission for SemEval-2019 Task 4: Hyperpartisan News Detection. Hyperpartisan news articles are sharply polarized and extremely biased (one-sided). It shows blind beliefs, opinions and unreasonable adherence to a party, idea, faction or a person. Through this task, we aim to develop an automated system that can be used to detect hyperpartisan news and serve as a prescreening technique for fake news detection. The proposed system jointly uses a rich set of handcrafted textual and semantic features. Our system achieved 2nd rank on the primary metric (82.0% accuracy) and 1st rank on the secondary metric (82.1% F1-score), among all participating teams. Comparison with the best performing system on the leaderboard1 shows that our system is behind by only 0.2% absolute difference in accuracy. © 2019 Association for Computational Linguistics",included,,Semantics;Absolute difference;Automated systems;F1 scores;Lexical features;News articles;Participating teams;Prescreening;Semantic features;Textual features;Automation,,
rayyan-1120387496,Steve Martin at SemEval-2019 task 4: Ensemble learning model for detecting hyperpartisan news,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,990-994,"Joo, Y. and Hwang, I.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091900275&partnerID=40&md5=14a238159bef9c61b55ecdb6c79bb24d,,,,"This paper describes our submission to task 4 in SemEval 2019, i.e., hyperpartisan news detection. Our model aims at detecting hyperpartisan news by incorporating the style-based features and the content-based features. We extract a broad number of feature sets and use as our learning algorithms the GBDT and the n-gram CNN model. Finally, we apply the weighted average for effective learning between the two models. Our model achieves an accuracy of 0.745 on the test set in subtask A. © 2019 Association for Computational Linguistics",included,,Learning algorithms;Semantics;CNN models;Content-based features;Effective learning;Ensemble learning;Features sets;Learning models;N-grams;Subtask;Test sets;Weighted averages;Learning systems;Learning,,
rayyan-1120387497,Dick-Preston and Morbo at SemEval-2019 task 4: Transfer learning for hyperpartisan news detection,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,939-943,"Isbister, T. and Johansson, F.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089224552&partnerID=40&md5=91e69742eef35a2a00c23e219d34d82a,,,,"In a world of information operations, influence campaigns, and fake news, classification of news articles as following hyperpartisan argumentation or not is becoming increasingly important. We present a deep learning-based approach in which a pre-trained language model has been fine-tuned on domain-specific data and used for classification of news articles, as part of the SemEval-2019 task on hyperpartisan news detection. The suggested approach yields accuracy and F1-scores around 0.8 which places the best performing classifier among the top-5 systems in the competition. © 2019 Association for Computational Linguistics",included,,Computational linguistics;Deep learning;Semantics;Domain specific;F1 scores;Information operations;Language model;Learning-based approach;News articles;Preston;Transfer learning;Classification (of information),,
rayyan-1120387498,TakeLab at SemEval-2019 task 4: Hyperpartisan news detection,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,995-998,"Palić, N. and Vladika, J. and Čubelić, D. and Lovrenčić, I. and Buljan, M. and Šnajder, J.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117560123&partnerID=40&md5=e3382f90fbfc92edb78e6ffdd948020e,,,,"In this paper, we demonstrate the system built to solve the SemEval-2019 task 4: Hyperpartisan News Detection (Kiesel et al., 2019), the task of automatically determining whether an article is heavily biased towards one side of the political spectrum. Our system receives an article in its raw, textual form, analyzes it, and predicts with moderate accuracy whether the article is hyperpartisan. The learning model used was primarily trained on a manually prelabeled dataset containing news articles. The system relies on the previously constructed SVM model, available in the Python Scikit-Learn library. We ranked 6th in the competition of 42 teams with an accuracy of 79.1% (the winning team had 82.2%). © 2019 Association for Computational Linguistics",included,,Semantics;Support vector machines;Form analysis;Learn+;Learning models;News articles;Spectra's;SVM model;Python,,
rayyan-1120387499,Team Kermit-the-frog at SemEval-2019 task 4: Bias detection through sentiment analysis and simple linguistic features,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1016-1020,"Anthonio, T. and Kloppenburg, L.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118549579&partnerID=40&md5=66c3a328135fa331b64bb62f0a340c66,,,,"In this paper we describe our participation in the SemEval 2019 shared task on hyperpartisan news detection. We present the system that we submitted for final evaluation and the three approaches that we used: sentiment, bias-laden words and filtered n-gram features. Our submitted model is a Linear SVM that solely relies on the negative sentiment of a document. We achieved an accuracy of 0.621 and a f1 score of 0.694 in the competition, revealing the predictive power of negative sentiment for this task. There was no major improvement by adding or substituting the features of the other two approaches that we tried. © 2019 Association for Computational Linguistics",included,,Semantics;F1 scores;Linear SVM;Linguistic features;N-grams;Negative sentiments;Predictive power;Sentiment analysis;Simple++;Bias (Epidemiology),,
rayyan-1120387500,Team Howard Beale at SemEval-2019 task 4: Hyperpartisan news detection with BERT,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,1007-1011,"Mutlu, O. and Can, O.A. and Dayanık, E.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118547951&partnerID=40&md5=a747cd892ee8906a2403f0ba002a6db7,,,,"This paper describes our system for SemEval-2019 Task 4: Hyperpartisan News Detection (Kiesel et al., 2019). We use pretrained BERT (Devlin et al., 2018) architecture and investigate the effect of different fine tuning regimes on the final classification task. We show that additional pretraining on news domain improves the performance on the Hyperpartisan News Detection task. Our system1 ranked 8th out of 42 teams with 78.3% accuracy on the held-out test dataset. © 2019 Association for Computational Linguistics",included,,Classification (of information);Computational linguistics;Semantics;Classification tasks;Detection tasks;Fine tuning;News domain;Performance;Pre-training;Statistical tests,,
rayyan-1120387501,Doris Martin at SemEval-2019 task 4: Hyperpartisan news detection with generic semi-supervised features,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,944-948,"Agerri, R.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101486062&partnerID=40&md5=962537f1823c1ddad05581c84a7944a5,,,,"In this paper we describe our participation to the Hyperpartisan News Detection shared task at SemEval 2019. Motivated by the late arrival of Doris Martin, we test a previously developed document classification system which consists of a combination of clustering features implemented on top of some simple shallow local features. We show how leveraging distributional features obtained from large in-domain unlabeled data helps to easily and quickly develop a reasonably good performing system for detecting hyperpartisan news. The system and models generated for this task are publicly available. © 2019 Association for Computational Linguistics",included,,Classification (of information);Computational linguistics;Information retrieval systems;Semantics;Clustering feature;Distributional features;Document classification systems;Late arrival;Local feature;Semi-supervised;Simple++;Unlabeled data;Feature extraction,,
rayyan-1120387502,Orwellian-times at SemEval-2019 task 4: A stylistic and content-based classifier,2019,,,"NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop",,,,976-980,"Knauth, J.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118576533&partnerID=40&md5=efeee55b4e36426e8715af17550716c7,,,,"While fake news detection received quite a bit of attention in recent years, hyperpartisan news detection is still an underresearched topic. This paper presents our work towards building a classification system for hyperpartisan news detection in the context of the SemEval2019 shared task 4. We experiment with two different approaches - a more stylistic one, and a more content related one - achieving average results. © 2019 Association for Computational Linguistics",included,,Classification system;Content-based classifiers;Classification (of information),,
rayyan-1120387503,Beyond “fake news”: Analytic thinking and the detection of false and hyperpartisan news headlines,2021,,,Judgment and Decision Making,,16,2,484-504,"Ross, R.M. and R and , D.G. and Pennycook, G.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104024577&partnerID=40&md5=c9148f7a886472f22fc42d8f852fc489,,,,"Why is misleading partisan content believed and shared? An influential account posits that political partisanship pervasively biases reasoning, such that engaging in analytic thinking exacerbates motivated reasoning and, in turn, the acceptance of hyper- partisan content. Alternatively, it may be that susceptibility to hyperpartisan content is explained by a lack of reasoning. Across two studies using different participant pools (total N = 1,973 Americans), we had participants assess true, false, and hyperpartisan news headlines taken from social media. We found no evidence that analytic thinking was associated with judging politically consistent hyperpartisan or false headlines to be accurate and unbiased. Instead, analytic thinking was, in most cases, associated with an increased tendency to distinguish true headlines from both false and hyperpar- tisan headlines (and was never associated with decreased discernment). These results suggest that reasoning typically helps people differentiate between low and high qual- ity political news, rather than facilitate belief in misleading content. Because social media play an important role in the dissemination of misinformation, we also inves- tigated willingness to share headlines on social media. We found a similar pattern whereby analytic thinking was not generally associated with increased willingness to share hyperpartisan or false headlines. Together, these results suggest a positive role for reasoning in resisting misinformation. © 2021, Society for Judgment and Decision making. All rights reserved.",other_task,,Dual-process theory;Fake news;Misinformation;News media;Partisanship;Thinking,,
rayyan-1120387504,Evaluating the News: (Mis)Perceptions of Objectivity and Credibility,2019,6,,Political Behavior,1909320,41,2,445-471,"Kelly, Dimitri",https://www.proquest.com/scholarly-journals/evaluating-news-mis-perceptions-objectivity/docview/2018438308/se-2?accountid=17253 https://iacobus.usc.gal/openurl/34CISUG_USC/34CISUG_USC:VU1?&genre=article&issn=01909320&title=Evaluating+the+News%253A+%2528Mis%2529Perceptions+of+Objectivity+and+Credibility&volume=41&issue=2&date=2019&atitle=Evaluating+the+News%253A+%2528Mis%2529Perceptions+of+Objectivity+and+Credibility&spage=445&sid=ProQ%253Apsychology&author=Kelly https://doi.org/10.1007/s11109-018-9458-4,English,Springer Nature B.V.,"Department of Political Science, Linfield College, Mcminnville, OR, USA ; Department of Political Science, Linfield College, Mcminnville, OR, USA New York","The introduction and popularity of politically biased news sources represents a significant historical shift in the media environment, with important unexplored consequences. Evidence points to partisan segmentation in the contemporary news market, but while assumptions abound, the mechanism driving consumers to sort along party lines is unclear. I develop a framework for news choice based on perceptions of objectivity and credibility and report a test of its central mechanism using a nationally representative survey experiment. I find support for a congenial media effect, where news content from an unfamiliar source is seen as more credible and less biased when it is consistent with existing beliefs, while balanced news content may be dismissed as less credible and biased. Previous studies have examined how perceptions of bias in identical news content can change when it is attributed to different sources. In todayâ€™s media world however, access to more news sources generally and the ease with which content from those sources can be shared makes it increasingly likely people will be exposed to news content from either unknown or potentially fake news sources. This study contributes to the literature by identifying the unique effect of message content on perceptions of news bias and source credibility, while holding source constant. Paradoxically, my findings indicate that political selective exposure may arise out of individualsâ€™ genuine desire for unbiased news.",not_pertinent,10.1007/s11109-018-9458-4,Political Science;Media bias;Ideological bias;News choice;Heuristics;Hostile media effect;Partisanship;Credibility;Mass media effects;Consumers;Political parties;Bias;Heuristic;Objectivity,,
rayyan-1120387505,What Is (Fake) News? Analyzing News Values (and More) in Fake Stories,2021,,,Media and Communication,,9,1,110-119,"T and oc, Edson C., Jr and Thomas, Ryan J. and Bishop, Lauren",https://www.proquest.com/scholarly-journals/what-is-fake-news-analyzing-values-more-stories/docview/2511142898/se-2?accountid=17253 https://iacobus.usc.gal/openurl/34CISUG_USC/34CISUG_USC:VU1?&genre=article&issn=&title=What+Is+%2528Fake%2529+News%253F+Analyzing+News+Values+%2528and+More%2529+in+Fake+Stories&volume=9&issue=1&date=2021&atitle=What+Is+%2528Fake%2529+News%253F+Analyzing+News+Values+%2528and+More%2529+in+Fake+Stories&spage=110&sid=ProQ%253Apubliccontent&author=Tandoc https://doi.org/10.17645/mac.v9i1.3331,English,Cogitatio Press,Lisbon,"â€˜Fake newsâ€™ has been a topic of controversy during and following the 2016 U.S. presidential election. Much of the scholarship on it to date has focused on the â€˜fakenessâ€™ of fake news, illuminating the kinds of deception involved and the motivations of those who deceive. This study looks at the â€˜newsnessâ€™ of fake news by examining the extent to which it imitates the characteristics and conventions of traditional journalism. Through a content analysis of 886 fake news articles, we find that in terms of news values, topic, and formats, articles published by fake news sites look very much like traditional—and real—news. Most of their articles included the news values of timeliness, negativity, and prominence; were about government and politics; and were written in an inverted pyramid format. However, one point of departure is in terms of objectivity, operationalized as the absence of the authorâ€™s personal opinion. The analysis found that the majority of articles analyzed included the opinion of their author or authors.",other_task,10.17645/mac.v9i1.3331,Communications;content analysis;disinformation;fake news;inverted pyramid;news values;objectivity;traditional news;News;Elections;Journalism;Values;Politics;Conventions;Deception;Communication;Social networks;False information;Conspiracy;Presidential elections;Partisanship,,
rayyan-1120387506,Sentiment Analysis for Fake News Detection,2021,,,Electronics,,10,11,1348,"Vilares, David and Gómez-Rodríguez, Carlos and Vilares, Jesús",https://www.proquest.com/scholarly-journals/sentiment-analysis-fake-news-detection/docview/2539625328/se-2?accountid=17253 https://iacobus.usc.gal/openurl/34CISUG_USC/34CISUG_USC:VU1?&genre=article&issn=&title=Sentiment+Analysis+for+Fake+News+Detection&volume=10&issue=11&date=2021&atitle=Sentiment+Analysis+for+Fake+News+Detection&spage=1348&sid=ProQ%253Apubliccontent&author=Vilares https://doi.org/10.3390/electronics10111348,English,MDPI AG,Basel,"In recent years, we have witnessed a rise in fake news, i.e., provably false pieces of information created with the intention of deception. The dissemination of this type of news poses a serious threat to cohesion and social well-being, since it fosters political polarization and the distrust of people with respect to their leaders. The huge amount of news that is disseminated through social media makes manual verification unfeasible, which has promoted the design and implementation of automatic systems for fake news detection. The creators of fake news use various stylistic tricks to promote the success of their creations, with one of them being to excite the sentiments of the recipients. This has led to sentiment analysis, the part of text analytics in charge of determining the polarity and strength of sentiments expressed in a text, to be used in fake news detection approaches, either as a basis of the system or as a complementary element. In this article, we study the different uses of sentiment analysis in the detection of fake news, with a discussion of the most relevant elements and shortcomings, and the requirements that should be met in the near future, such as multilingualism, explainability, mitigation of biases, or treatment of multimedia elements.",other_task,10.3390/electronics10111348,Electronics;sentiment analysis;opinion mining;fake news;social media;News;Propaganda;Data mining;False information;Conspiracy;Politics;Social networks;Gossip;Multimedia,,
rayyan-1120387507,H-Prop and H-Prop-News: Computational Propaganda Datasets in Hindi,2022,,,Data,,7,3,29,"Chaudhari, Deptii and Pawar, Ambika Vishal and Barrón-Cedeño, Alberto",https://www.proquest.com/scholarly-journals/h-prop-news-computational-propaganda-datasets/docview/2642397545/se-2?accountid=17253 https://iacobus.usc.gal/openurl/34CISUG_USC/34CISUG_USC:VU1?&genre=article&issn=&title=H-Prop+and+H-Prop-News%253A+Computational+Propaganda+Datasets+in+Hindi&volume=7&issue=3&date=2022&atitle=H-Prop+and+H-Prop-News%253A+Computational+Propaganda+Datasets+in+Hindi&spage=29&sid=ProQ%253Apubliccontent&author=Chaudhari https://doi.org/10.3390/data7030029,English,MDPI AG,"Department of CS & IT, Symbiosis Institute of Technology (SIT), Symbiosis International (Deemed University), Pune 412115, India ; Department of Interpreting and Translation, Alma Mater Studiorum-Università di Bologna, Corso della Repubblica 136, 47121 Forlì, Italy; a.barron@unibo.it ; Department of CS & IT, Symbiosis Institute of Technology (SIT), Symbiosis International (Deemed University), Pune 412115, India Basel","In this digital era, people rely on the internet for their news consumption. As people are free to express their opinions on social media, much information shared on the internet is loaded with propaganda. Propagandist contents are intended to influence public opinion. In the mainstream media or prominent news agencies, the authorsâ€™ and news agenciesâ€™ own bias may impact in the news contents. Hence, it is required to detect such propaganda spread through news articles. Detection and classification of propagandist text require standard, high-quality, annotated datasets. A few datasets are available for propaganda classification. However, these datasets are mostly in English. Hindi is the most spoken language in India, and efforts are needed to detect its propagandist contents. This research work introduces two new datasets: H-Prop and H-Prop-News, which consist of news articles in Hindi annotated as propaganda or non-propaganda. The H-Prop dataset is generated by translating 28,630 news articles from the QProp dataset. The H-Prop-News dataset contains 5500 news articles collected from 32 prominent Hindi news websites. We experiment with the proposed datasets using four supervised machine learning models combined with different feature vectors and word embeddings. Our experiments achieve 87% accuracy using Logistic Regression with TF-IDF feature vectors. The datasets provide high-quality labeled news articles in Hindi and open new avenues for researchers to explore techniques for analyzing and classifying propaganda in Hindi text.Dataset:https://zenodo.org/record/5828240#.YduLv2hBxPY.Dataset License: Creative Commons Attribution 4.0 International",other_task,10.3390/data7030029,Sciences: Comprehensive Works;propaganda identification;news articles analysis;Hindi text processing;Language;Translating;Datasets;Classification;Internet;Websites;News;Supervision;Propaganda;Machine learning;Annotations;Translations;Media coverage;Bias;India,,
rayyan-1120387508,Research on Fake News Detection Based on Diffusion Growth Rate,2022,,,Wireless Communications & Mobile Computing (Online),1530-8669,2022,,,"Chen, Jinyin and Jia, Chengyu and Li, Qinfeng and Zheng, Haibin and Zhao, Wenhong and Yan, Mingyuan and Lin, Changting and Yu, Lei",https://www.proquest.com/scholarly-journals/research-on-fake-news-detection-based-diffusion/docview/2693600067/se-2?accountid=17253 https://iacobus.usc.gal/openurl/34CISUG_USC/34CISUG_USC:VU1?&genre=article&issn=15308669&title=Research+on+Fake+News+Detection+Based+on+Diffusion+Growth+Rate&volume=2022&issue=&date=2022&atitle=Research+on+Fake+News+Detection+Based+on+Diffusion+Growth+Rate&spage=&sid=ProQ%253Apubliccontent&author=Chen https://doi.org/10.1155/2022/6329014,English,Hindawi Limited,"Institute of Cyberspace Security, Zhejiang University of Technology, 310023, China; College of Information Engineering, Zhejiang University of Technology, 310023, China ; College of Information Engineering, Zhejiang University of Technology, 310023, China ; College of Information Engineering, Jiaxing Nanhu University, 314001, China ; Mike Cottrell College of Business, University of North Georgia, GA 30597, USA ; Zhejiang University, 310014, China; Binjiang Institute of Zhejiang University, 310014, China ; Institute of Cyberspace Security, Zhejiang University of Technology, 310023, China; College of Information Engineering, Zhejiang University of Technology, 310023, China Oxford","With the rapid development of the Internet, social media has become a convenient online platform for users to obtain information, express opinions, and communicate with each other. Users are keen to participate in discussions on hot topics and exchange opinions on social media. A lot of fake news has also arisen at this moment. However, existing fake news detection methods have the problem of relying too much on textual features. Textual features are easy to be tampered with and deceive the detector; thus, it is difficult to distinguish fake news only by relying on textual features. To address the challenge, we propose a fake news detection method based on the diffusion growth rate (Delta-G). To identify the real and fake news, Delta-G uses graph convolutional networks to extract the diffusion structure features and then adopts the long-short-term memory networks to extract the growth rate features on time series. In the experiments, Delta-G is verified on two news datasets, Twitter and Weibo. Compared with the three detection methods of decision tree classifier, support vector machines with a propagation tree kernel, and RvNN, the accuracy of the Delta-G on the two datasets is improved by an average of 5% or more, which is better than all the baselines.",other_task,10.1155/2022/6329014,Computers;Feature extraction;Deep learning;Social networks;Support vector machines;News;Authenticity;Earthquakes;Diffusion rate;Methods;Time series;Digital media;Decision trees;Semantics;Datasets;Artificial intelligence;Nepal,,
rayyan-1120387509,Multi-Stage Prompt Tuning for Political Perspective Detection in Low-Resource Settings,2023,,,Applied Sciences,,13,10,6252,"Kang-Min, Kim and Lee, Mingyu and Won, Hyun-Sik and Min-Ji, Kim and Kim, Yeachan and Lee, SangKeun",https://www.proquest.com/scholarly-journals/multi-stage-prompt-tuning-political-perspective/docview/2819307896/se-2?accountid=17253 https://iacobus.usc.gal/openurl/34CISUG_USC/34CISUG_USC:VU1?&genre=article&issn=&title=Multi-Stage+Prompt+Tuning+for+Political+Perspective+Detection+in+Low-Resource+Settings&volume=13&issue=10&date=2023&atitle=Multi-Stage+Prompt+Tuning+for+Political+Perspective+Detection+in+Low-Resource+Settings&spage=6252&sid=ProQ%253Apubliccontent&author=Kang-Min https://doi.org/10.3390/app13106252,English,MDPI AG,"Department of Data Science, The Catholic University of Korea, Bucheon 14662, Republic of Korea; kangmin89@catholic.ac.kr; Department of Artificial Intelligence, The Catholic University of Korea, Bucheon 14662, Republic of Korea; abugda@catholic.ac.kr (H.-S.W.); kimmin122@catholic.ac.kr (M.-J.K.) ; Department of Artificial Intelligence, Korea University, Seoul 02841, Republic of Korea; decon9201@korea.ac.kr (M.L.); yeachan@korea.ac.kr (Y.K.) ; Department of Artificial Intelligence, The Catholic University of Korea, Bucheon 14662, Republic of Korea; abugda@catholic.ac.kr (H.-S.W.); kimmin122@catholic.ac.kr (M.-J.K.) ; Department of Artificial Intelligence, Korea University, Seoul 02841, Republic of Korea; decon9201@korea.ac.kr (M.L.); yeachan@korea.ac.kr (Y.K.); Department of Computer Science and Engineering, Korea University, Seoul 02841, Republic of Korea ; Department of Data Science, The Catholic University of Korea, Bucheon 14662, Republic of Korea; kangmin89@catholic.ac.kr; Department of Artificial Intelligence, The Catholic University of Korea, Bucheon 14662, Republic of Korea; abugda@catholic.ac.kr (H.-S.W.); kimmin122@catholic.ac.kr (M.-J.K.) Basel","Political perspective detection in news media—identifying political bias in news articles—is an essential but challenging low-resource task. Prompt-based learning (i.e., discrete prompting and prompt tuning) achieves promising results in low-resource scenarios by adapting a pre-trained model to handle new tasks. However, these approaches suffer performance degradation when the target task involves a textual domain (e.g., a political domain) different from the pre-training task (e.g., masked language modeling on a general corpus). In this paper, we develop a novel multi-stage prompt tuning framework for political perspective detection. Our method involves two sequential stages: a domain- and task-specific prompt tuning stage. In the first stage, we tune the domain-specific prompts based on a masked political phrase prediction (MP3) task to adjust the language model to the political domain. In the second task-specific prompt tuning stage, we only tune task-specific prompts with a frozen language model and domain-specific prompts for downstream tasks. The experimental results demonstrate that our method significantly outperforms fine-tuning (i.e., model tuning) methods and state-of-the-art prompt tuning methods on the SemEval-2019 Task 4: Hyperpartisan News Detection and AllSides datasets.",included,10.3390/app13106252,Sciences: Comprehensive Works;political bias detection;pre-trained language model;prompt-based learning;prompt tuning;self-supervised learning;Politics;Language;Digital music;News media;Teaching methods;Performance degradation;Performance evaluation;Natural language;Health Resources,,
rayyan-1120387510,Politically-oriented information inference from text,2023,,,Journal of Universal Computer Science,0948695X,29,6,569-594,"da Silva, Samuel Caetano and Paraboni, Iv and re",https://www.proquest.com/scholarly-journals/politically-oriented-information-inference-text/docview/2836315083/se-2?accountid=17253 https://iacobus.usc.gal/openurl/34CISUG_USC/34CISUG_USC:VU1?&genre=article&issn=0948695X&title=Politically-oriented+information+inference+from+text&volume=29&issue=6&date=2023&atitle=Politically-oriented+information+inference+from+text&spage=569&sid=ProQ%253Apubliccontent&author=Samuel+Caetano+da+Silva https://doi.org/10.3897/jucs.96652,English,Pensoft Publishers,Bristol,"The inference of politically-oriented information from text data is a popular research topic in Natural Language Processing (NLP) at both text- and author-level. In recent years, studies of this kind have been implemented with the aid of text representations ranging from simple count-based models (e.g., bag-of-words) to sequence-based models built from transformers (e.g., BERT). Despite considerable success, however, we may still ask whether results may be improved further by combining these models with additional text representations. To shed light on this issue, the present work describes a series of experiments to compare a number of strategies for political bias and ideology inference from text data using sequence-based BERT models, syntax-and semantics-driven features, and examines which of these representations (or their combinations) improve overall model accuracy. Results suggest that one particular strategy - namely, the combination of BERT language models with syntactic dependencies - significantly outperforms well-known count- and sequence-based text classifiers alike. In particular, the combined model has been found to improve accuracy across all tasks under consideration, outperforming the SemEval hyperpartisan news detection top-performing system by up to 6%, and outperforming the use of BERT alone by up to 21%, making a potentially strong case for the use of heterogeneous text representations in the present tasks.",included,10.3897/jucs.96652,Computers;Natural language processing;Text classification;Politically-oriented inference;Sentiment analysis;Author profiling;Model accuracy;Semantics;Representations;Inference,,
rayyan-1120387511,Stylometric Fake News Detection Based on Natural Language Processing Using Named Entity Recognition: In-Domain and Cross-Domain Analysis,2023,,,Electronics,,12,17,3676,"Tsai, Chih-Ming",https://www.proquest.com/scholarly-journals/stylometric-fake-news-detection-based-on-natural/docview/2862243840/se-2?accountid=17253 https://iacobus.usc.gal/openurl/34CISUG_USC/34CISUG_USC:VU1?&genre=article&issn=&title=Stylometric+Fake+News+Detection+Based+on+Natural+Language+Processing+Using+Named+Entity+Recognition%253A+In-Domain+and+Cross-Domain+Analysis&volume=12&issue=17&date=2023&atitle=Stylometric+Fake+News+Detection+Based+on+Natural+Language+Processing+Using+Named+Entity+Recognition%253A+In-Domain+and+Cross-Domain+Analysis&spage=3676&sid=ProQ%253Apubliccontent&author=Tsai https://doi.org/10.3390/electronics12173676,English,MDPI AG,Basel,"Nowadays, the dissemination of news information has become more rapid, liberal, and open to the public. People can find what they want to know more and more easily from a variety of sources, including traditional news outlets and new social media platforms. However, at a time when our lives are glutted with all kinds of news, we cannot help but doubt the veracity and legitimacy of these news sources; meanwhile, we also need to guard against the possible impact of various forms of fake news. To combat the spread of misinformation, more and more researchers have turned to natural language processing (NLP) approaches for effective fake news detection. However, in the face of increasingly serious fake news events, existing detection methods still need to be continuously improved. This study proposes a modified proof-of-concept model named NER-SA, which integrates natural language processing (NLP) and named entity recognition (NER) to conduct the in-domain and cross-domain analysis of fake news detection with the existing three datasets simultaneously. The named entities associated with any particular news event exist in a finite and available evidence pool. Therefore, entities must be mentioned and recognized in this entity bank in any authentic news articles. A piece of fake news inevitably includes only some entitlements in the entity bank. The false information is deliberately fabricated with fictitious, imaginary, and even unreasonable sentences and content. As a result, there must be differences in statements, writing logic, and style between legitimate news and fake news, meaning that it is possible to successfully detect fake news. We developed a mathematical model and used the simulated annealing algorithm to find the optimal legitimate area. Comparing the detection performance of the NER-SA model with current state-of-the-art models proposed in other studies, we found that the NER-SA model indeed has superior performance in detecting fake news. For in-domain analysis, the accuracy increased by an average of 8.94% on the LIAR dataset and 19.36% on the fake or real news dataset, while the F1-score increased by an average of 24.04% on the LIAR dataset and 19.36% on the fake or real news dataset. In cross-domain analysis, the accuracy and F1-score for the NER-SA model increased by an average of 28.51% and 24.54%, respectively, across six domains in the FakeNews AMT dataset. The findings and implications of this study are further discussed with regard to their significance for improving accuracy, understanding context, and addressing adversarial attacks. The development of stylometric detection based on NLP approaches using NER techniques can improve the effectiveness and applicability of fake news detection.",other_task,10.3390/electronics12173676,Electronics;fake news;stylometric detection;natural language processing (NLP);named entity recognition (NER);Language;Accuracy;Readability;Machine learning;Datasets;Deep learning;Sentiment analysis;Mathematical models;Hypotheses;Credibility;Recognition;Social networks;Support vector machines;News;Algorithms;Natural language processing;Linguistics;False information;Simulated annealing;Semantics;Sentences,,
rayyan-1120387512,Identifying Media Bias beyond Words: Using Automatic Identification of Persuasive Techniques for Media Bias Detection,2023,9,,Procesamiento del Lenguaje Natural,11355948,71,,179-190,"Rodrigo-Ginés, Francisco-Javier and Carrillo-de-Albornoz, Jorge and Plaza, Laura",https://www.proquest.com/scholarly-journals/identifying-media-bias-beyond-words-using/docview/2868088327/se-2?accountid=17253 https://iacobus.usc.gal/openurl/34CISUG_USC/34CISUG_USC:VU1?&genre=article&issn=11355948&title=Identifying+Media+Bias+beyond+Words%253A+Using+Automatic+Identification+of+Persuasive+Techniques+for+Media+Bias+Detection&volume=71&issue=&date=2023&atitle=Identifying+Media+Bias+beyond+Words%253A+Using+Automatic+Identification+of+Persuasive+Techniques+for+Media+Bias+Detection&spage=179&sid=ProQ%253Allba&author=Francisco-Javier+Rodrigo-Gin%25C3%25A9s,English,Sociedad Española para el Procesamiento del Lenguaje Natural,Jaén,"Detecting media bias is a challenging task due to the complexity and ambiguity of language. Current approaches are limited in their ability to generalise across regions and styles of journalism. This paper proposes a new approach that focusses on detecting rhetorical linguistic techniques rather than just analysing words or contextual representations. We compare three different systems based on different techniques for identifying media bias, including a lexical-based system, a language transformers-based system, and a cascade transformers system that relies on persuasive techniques detection. We have evaluated these systems using a Ukraine crisis news dataset and splitting it by according to the country to generate training and test sets, i.e. different sets for each country. The results of the cascade system outperforms by at least a 6% the other approaches in identifying media bias when evaluating with different countries setup. Our results suggest that models capable of detecting rhetorical and persuasive linguistic techniques are necessary to generalise media bias effectively.Alternate abstract:Detectar sesgo mediÃ¡tico es una tarea desafiante debido a la ambigÃ¼edad del lenguaje. Los enfoques actuales tienen dificultades para generalizar entre regiones y estilos periodÃ­sticos. Proponemos un enfoque centrado en la detecciÃ³n de tÃ©cnicas lingÃ¼Ã­sticas en lugar de analizar palabras o representaciones contextuales. Comparamos tres sistemas diferentes basados en diferentes tÃ©cnicas para identificar el sesgo de los medios: un sistema basado en lÃ©xico, un sistema basado en transformers y un sistema de transformers en cascada capaz de detectar tÃ©cnicas persuasivas. Hemos evaluado estos sistemas utilizando un conjunto de datos de noticias de la guerra de Ucrania. Los resultados del sistema en cascada superan en al menos un 6% a los demÃ¡s enfoques a la hora de identificar el sesgo de los medios de diferentes paÃ­ses. Nuestros resultados sugieren que los modelos capaces de detectar tÃ©cnicas lingÃ¼Ã­sticas retoricas y persuasivas son necesarios para generalizar la detecciÃ³n de sesgo de los medios de manera efectiva.",other_task,,Linguistics;Computer Applications;Generalization;Bias;Words (language);Transformers;Natural language generation;Persuasion;Media;Media coverage;Journalism;Journalistic language;Bias (Epidemiology),,
